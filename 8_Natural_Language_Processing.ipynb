{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8_Natural_Language_Processing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM9XyIFGzjGA"
      },
      "source": [
        "# Introduction to NLP Fundementals\n",
        "\n",
        "NLP has the goal of deriving information out of natural language (could be sequences text or speech).\n",
        "\n",
        "Another common term for NLP problems is sequence to sequence problems (seq2seq)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeJiXT0X8qPn"
      },
      "source": [
        "## Check for GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmTSoIrF8wQb",
        "outputId": "85550a70-72ec-466a-8011-6e641131e993"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla K80 (UUID: GPU-06221764-48d3-8d7e-eee7-f83b229141a5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp8DZTMN80-a",
        "outputId": "a16c42b5-8ba6-424e-bb1b-8f3674e9dcb8"
      },
      "source": [
        "## Get helper functions from https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/helper_functions.py\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-15 13:09:43--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-11-15 13:09:43 (74.9 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeuPaX1Q9HZL"
      },
      "source": [
        "## Get a text dataset\n",
        "\n",
        "The dataset we are going to be using is kaggle's introduction to NLP dataset (text samples of Tweets labelled as disaster or not disaster).\n",
        "\n",
        "See the original source here: https://www.kaggle.com/c/nlp-getting-started"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7PNKWTw969G",
        "outputId": "873fd863-3179-4a33-b96c-b86b18b1863e"
      },
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "\n",
        "# unzip data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-15 13:09:45--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.120.128, 142.250.128.128, 142.251.6.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.120.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2021-11-15 13:09:45 (101 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcQdV1Ib-i7j"
      },
      "source": [
        "## Visualizing a text dataset\n",
        "\n",
        "To visualize our text samples, we first have to read them in, one way to do so  would be to use Python: https://realpython.com/read-write-files-python/\n",
        "\n",
        "But I prefer to get visual straight away.\n",
        "\n",
        "So, another way to do this is using Pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "a9xBbZBW_D-M",
        "outputId": "e5c246f7-d41d-496d-db04-8ccfa87011ed"
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "HgqDSYnOAI2N",
        "outputId": "fede3c8f-7540-4f10-e348-f66a79a027bc"
      },
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "train_df_shuffled.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ZR7GJIOzAT2p",
        "outputId": "5d698330-a25b-450b-81ba-e4f000fa7a11"
      },
      "source": [
        "# What does test data frame looks like?\n",
        "test_df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCO3qyRQA4rz",
        "outputId": "29377ab0-c4dd-4520-c058-972251239bcf"
      },
      "source": [
        "# How many examples of each class are there?\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDS7aWJRBDpR",
        "outputId": "e6e0c32a-43b7-4da4-c510-469fc7da5e1b"
      },
      "source": [
        "# How many total samples?\n",
        "len(train_df), len(test_df)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfmW6PFGBlV6",
        "outputId": "a36bbd13-a449-4008-8415-4daf1310aa27"
      },
      "source": [
        "# Let's visualize some random training examples\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df) - 5) # create random indexes not higher than the total number of samples\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Did I drink too much? Am I losing touch? Did I build a ship to wreck?\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Police expand search for missing pregnant woman in Beloeil: Police in Richelieu-Saint-Laurent are expanding th... http://t.co/hMuyzmv8qH\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "An outbreak of Legionnaires' disease in New York has killed at least 8 people ÛÓ now officials think they've fo... http://t.co/7evyeLW4LC\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Enter the world of extreme diving ÛÓ 9 stories up and into the Volga River http://t.co/7adqV1gRVR\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Mr. T stopped wearing gold chains in 2005 because he thought it would be an insult to the people who lost everything after Hurricane Katrina\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdL9-d3mC0lu"
      },
      "source": [
        "### Split data into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS24GfpqDuSK"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnXh5mH8D6V0"
      },
      "source": [
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1,  # use 10% of training data for validation split\n",
        "                                                                            random_state=42)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51Oz0NQ5EsJa",
        "outputId": "f7e6c7b8-5594-4c3f-d32d-4a889a0bbbbd"
      },
      "source": [
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels) "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "747U84dJE8Rs",
        "outputId": "458ad7d4-8cd5-4983-8aa0-0a6c650adf72"
      },
      "source": [
        "# Cheeck the first 10 samples\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPKAxmtZE_hT"
      },
      "source": [
        "## Converting text into numbers\n",
        "\n",
        "When dealing with a text problem, one of the first things wou'll have to do before you can build a model is to convert your text to numbers.\n",
        "\n",
        "There are a few ways to do this, namely:\n",
        "* Tokenization - direct mapping of token (a token could be a word or character) to number\n",
        "* Embedding - create a matrix of feature vector for each token (the  size of the feature vector can be defined and this embedding can be learned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xkQ-3KxVsf9"
      },
      "source": [
        "### Text vectorization (tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QkaEw0NYVM1"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Use the default TextVectorization parameters\n",
        "text_vectorizer = TextVectorization(max_tokens=None,  # how many words in the vocabulary (automatically add <OOV>)\n",
        "                                    standardize=\"lower_and_strip_punctuation\",\n",
        "                                    split=\"whitespace\",\n",
        "                                    ngrams=None,  # Create groups of n words\n",
        "                                    output_mode=\"int\", # how to map tokens to numbers\n",
        "                                    output_sequence_length=None)  # how long do you want your sequences to be)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DkwuuNuYk45",
        "outputId": "e4b58e07-c356-4c34-ea3d-6ce02eff9683"
      },
      "source": [
        "# Find the average number of tokens (words) in the training tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsAUR5F4cYVO"
      },
      "source": [
        "# Setup text vectorization variables\n",
        "max_vocab_length = 10000  # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does a model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,  # how many words in the vocabulary (automatically add <OOV>)\n",
        "                                    output_mode=\"int\", # how to map tokens to numbers\n",
        "                                    output_sequence_length=max_length)  # how long do you want your sequences to be)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZtHZ8b5dk7E"
      },
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5pT2r_feCRN",
        "outputId": "d2a86346-f312-4e69-941e-5999a7a17c90"
      },
      "source": [
        "# Create a sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeL6FI3keRid",
        "outputId": "49cf01aa-0827-4bd5-bb8f-6b14b70d79df"
      },
      "source": [
        "# Choose a random sentence from training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\\n",
        "      \\n\\nVectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " @RAYCHIELOVESU On the block we hear sirens&amp; stories of kids getting Lemonade only to see their life get minute made. we talking semi paid      \n",
            "\n",
            "Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[9337,   11,    2, 1549,   46,  684, 8480, 1172,    6,  573,  209,\n",
              "           1,  126,    5,   99]])>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URYko2bIfAs9",
        "outputId": "cca09253-69b1-4d75-cfc6-455877213674"
      },
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary() # get all the unique words in our training data\n",
        "top_5_words = words_in_vocab[:5]  # get the most common words\n",
        "bottom_5_words = words_in_vocab[-5:]  # get the least common words\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"5 most common words: {top_5_words}\")\n",
        "print(f\"5 least comon words: {bottom_5_words}\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "5 least comon words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCjtDyVMgNqe"
      },
      "source": [
        "### Creating an Embedding using an Embedding layer\n",
        "\n",
        "To make our embedding, we're going to use TensorFlow's embedding layer: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
        "\n",
        "The parameters we care most about for our embedding layer:\n",
        "* `input_dim` = the size of our vocabulary\n",
        "* `output_dim` = the size of the output embedding vector, for example, a value of 100 would mean each token gets represented by a vector 100 long\n",
        "* `input_length` = length of the sequences being passed to the embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_cFBohar88x",
        "outputId": "604c2753-0325-4909-9a5c-4d7067fb6a35"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim = max_vocab_length,  # set the input shape\n",
        "                             output_dim = 128,  # output shape\n",
        "                             embeddings_initializer=\"uniform\",\n",
        "                             input_length=max_length  # how long is each input\n",
        "                             )\n",
        "\n",
        "embedding"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7f4f305b0990>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiRmGbYdtuNo",
        "outputId": "ec80e283-3237-4938-80ea-1f455b4dec0a"
      },
      "source": [
        "# Get a random sentence from the training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence} \\\n",
        "        \\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into dense vectors of fixed size)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " [Jax(MK2)] Stage Fatality:UUD+LK (Close)         \n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.00381092,  0.03243092,  0.04129322, ..., -0.01220999,\n",
              "          0.03927057, -0.04735548],\n",
              "        [ 0.03110098,  0.03563196, -0.01865891, ...,  0.04343868,\n",
              "          0.01666732,  0.01057909],\n",
              "        [ 0.00381092,  0.03243092,  0.04129322, ..., -0.01220999,\n",
              "          0.03927057, -0.04735548],\n",
              "        ...,\n",
              "        [-0.0452816 ,  0.04016448, -0.00283588, ...,  0.02750378,\n",
              "          0.02701677,  0.04658217],\n",
              "        [-0.0452816 ,  0.04016448, -0.00283588, ...,  0.02750378,\n",
              "          0.02701677,  0.04658217],\n",
              "        [-0.0452816 ,  0.04016448, -0.00283588, ...,  0.02750378,\n",
              "          0.02701677,  0.04658217]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgkIjpv6ueIv",
        "outputId": "3182b56f-9d90-4f53-fe71-3d5645360b4d"
      },
      "source": [
        "# Check out a single tokens embedding\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence[0]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([ 0.00381092,  0.03243092,  0.04129322, -0.02860317,  0.01489017,\n",
              "        -0.0107004 , -0.00999855,  0.00219028, -0.04089532, -0.02263336,\n",
              "        -0.04352074, -0.04009819,  0.02342454,  0.00478386,  0.02914963,\n",
              "        -0.00191321,  0.00358417, -0.04836839,  0.0325377 ,  0.04396391,\n",
              "         0.03103708, -0.02111561,  0.03539922, -0.03740489,  0.04604441,\n",
              "         0.02680707, -0.04603208, -0.00537141,  0.03901465, -0.02567453,\n",
              "         0.02653943,  0.04252673,  0.04739592,  0.0387325 ,  0.03176198,\n",
              "         0.04557294, -0.03617536,  0.01105507,  0.04954011,  0.03337005,\n",
              "        -0.01601331,  0.00552117, -0.01139329,  0.04909214, -0.00520103,\n",
              "         0.03840901,  0.00309901,  0.02862829,  0.0025895 , -0.02636516,\n",
              "         0.03910864, -0.03625961,  0.02094003, -0.02847647,  0.03550143,\n",
              "         0.04396692,  0.00284183,  0.03194529,  0.01765947,  0.04210656,\n",
              "        -0.0018664 ,  0.00440159, -0.03947011,  0.02995903, -0.0438288 ,\n",
              "         0.03351984,  0.04749078,  0.0464967 ,  0.00782461, -0.0090735 ,\n",
              "        -0.02177927, -0.00596763,  0.01405286, -0.00179769, -0.00719329,\n",
              "        -0.02920741,  0.03144362, -0.03928779, -0.03421146, -0.01084689,\n",
              "        -0.01251209, -0.01259422, -0.01212198,  0.04936799,  0.03068734,\n",
              "         0.01771089,  0.00819325,  0.04829783,  0.00526949, -0.0137523 ,\n",
              "        -0.00476427,  0.01020418, -0.00531213, -0.01642168,  0.04545386,\n",
              "         0.01514688,  0.02408409,  0.03325404,  0.0218943 , -0.01493311,\n",
              "         0.04379005,  0.00382581,  0.03844273, -0.01768699, -0.03751421,\n",
              "         0.02732411, -0.03319649, -0.01291274, -0.04653928,  0.01631684,\n",
              "        -0.01806201, -0.03152373, -0.0201505 ,  0.04937904,  0.03661883,\n",
              "        -0.01621098,  0.02704882,  0.01348614, -0.04305494, -0.02289839,\n",
              "         0.03645096,  0.04330273,  0.00681195, -0.04865786,  0.01733769,\n",
              "        -0.01220999,  0.03927057, -0.04735548], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " '[')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5akCCvNvED4"
      },
      "source": [
        "## Modelling a text dataset (running a series of experiments)\n",
        "\n",
        "Now we've got a way to turn text sequences into numbers, it's time to start building a series of modelling experiments.\n",
        "\n",
        "We'll start with a baseline and move on from there.\n",
        "\n",
        "* Model 0: Naive Bayes (baseline), this is from Sklear ML map: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
        "* Model 1: Feed-Forward Neural Network (dense model)\n",
        "* Model 2: LSTM Model (RNN)\n",
        "* Model 3: GRU model (RNN)\n",
        "* Model 4: Bidirectional-LSTM model (RNN)\n",
        "* Model 5: 1D Convolutional Neural Network (CNN)\n",
        "* Model 6: TensorFlow Hub pretrained Feature Extractor (using transfer learning for NLP)\n",
        "* Model 7: Same as model 6 with 10% of training data\n",
        "\n",
        "How are we going to approach all of these?\n",
        "\n",
        "Use the standard steps in modelling with TensorFLow#\n",
        "\n",
        "* Create a model\n",
        "* Build a model\n",
        "* Fit a model\n",
        "* Evaluate our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofBA3ULAwAZS"
      },
      "source": [
        "### Model 0: Getting a baseline\n",
        "\n",
        "As with all machine learning modelling experiment, it is important to create a baseline model so you've got a benchmar for future experiments to build upon.\n",
        "\n",
        "To create our baseline, we'll use sklearn's Multinomial Naive Bayes using the TF-IDF formular to convert our words to numbers.\n",
        "\n",
        "> 🔑 **Note:** It's common practice to use non-DL algorithms as baseline because of their speed and later using DL to see if you can improve upon them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdMbrci70vsa",
        "outputId": "c5e9a08f-8ed1-40ee-c2ad-a4134fa18f00"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB())  # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZKfZ1a_7awW",
        "outputId": "08836b09-0852-4325-d245-027967de4d5a"
      },
      "source": [
        "# Evaluate our baseline model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achieves a scroe of: {baseline_score*100:.2f}\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieves a scroe of: 79.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIJhT-d37qrL",
        "outputId": "19e5721c-1ec3-4da4-d35f-afc869345671"
      },
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n7DgxtK8Fww"
      },
      "source": [
        "### Creating an evaluation function for our model experiments\n",
        "\n",
        "We could evaluate our model's predictions with different metrics every time, however, this willbe cumbersome and could easily be fixed with a function.\n",
        "\n",
        "Let's create one to compare our model's prediction using truth labels using the following metrics:\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORj7zLOb9iBG"
      },
      "source": [
        "# Function to evaluate: accuracy,precision, recall and f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1-score using weighted average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                   \"precision\": model_precision,\n",
        "                   \"recall\": model_recall,\n",
        "                   \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DvJVEKk_hj1",
        "outputId": "55a18e85-20af-4281-acbc-ca8766230b13"
      },
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxwTtvWA_r_6"
      },
      "source": [
        "### Model 1: Feed-Forward Neural Network (dense model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOptNgfNZlF_"
      },
      "source": [
        "# Create a tensorboard callback (need to create a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create a directory to save tensorflow logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3ixqFFXaM2J"
      },
      "source": [
        "# Build model with the Functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\") # inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) # turn the input text into numbers\n",
        "x = embedding(x) # create an embedding of the numerized numbers\n",
        "x = layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embedding (try running the model without this layer and see what happens)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # create the output layer, want binary outputs so use sigmoid activation\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRdNkQa1bJ7O",
        "outputId": "81575028-b720-4176-fa32-16942f15f654"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQNtTAcHbMQt"
      },
      "source": [
        "# Compile the model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2V6BX1zbph1",
        "outputId": "47234620-ad2a-4778-e45e-03efa656d94b"
      },
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR, \n",
        "                                                                     experiment_name=\"simple_dense_model\")])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/simple_dense_model/20211115-130953\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 8ms/step - loss: 0.6097 - accuracy: 0.6954 - val_loss: 0.5369 - val_accuracy: 0.7454\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.4402 - accuracy: 0.8175 - val_loss: 0.4675 - val_accuracy: 0.7835\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.3454 - accuracy: 0.8584 - val_loss: 0.4607 - val_accuracy: 0.7927\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.2831 - accuracy: 0.8918 - val_loss: 0.4658 - val_accuracy: 0.7887\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.2369 - accuracy: 0.9127 - val_loss: 0.4833 - val_accuracy: 0.7887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpQHe5WMcUB-",
        "outputId": "2222d10c-3460-4c8b-e037-bbe866cb6184"
      },
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7887\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4833071529865265, 0.7887139320373535]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdhwXszNl1oH",
        "outputId": "69532f4d-d74b-4817-a176-b7075df66aaa"
      },
      "source": [
        "# Make some predictions and evaluate those\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5JEOaeimTvS",
        "outputId": "d24499ae-b3e7-4fb9-80e9-93726a122f92"
      },
      "source": [
        "# Look at a single prediction\n",
        "model_1_pred_probs[0]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.3531098], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eR3GC-lmcOf",
        "outputId": "cd5d71b1-8012-4ea8-81d5-412a2292065e"
      },
      "source": [
        "# Look at first 10 predictions\n",
        "model_1_pred_probs[:10]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.3531098 ],\n",
              "       [0.76771265],\n",
              "       [0.99722713],\n",
              "       [0.09336488],\n",
              "       [0.117157  ],\n",
              "       [0.9315556 ],\n",
              "       [0.9107082 ],\n",
              "       [0.99243706],\n",
              "       [0.9621432 ],\n",
              "       [0.22584191]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdICwbEHmgfK",
        "outputId": "421ac53b-ea68-46b9-8bd3-215574c5850b"
      },
      "source": [
        "# Convert model prediction probabilities to label format\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
        "model_1_preds[:20]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXhV6hgJm36P",
        "outputId": "b566e667-8cea-4ec1-87ee-014d24c073b4"
      },
      "source": [
        "# Calculate our model_1 results\n",
        "model_1_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.87139107611549,\n",
              " 'f1': 0.7855210885289512,\n",
              " 'precision': 0.7943691525527891,\n",
              " 'recall': 0.7887139107611548}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtYTcnH9nKmP",
        "outputId": "0b06eb8d-c08a-4df5-ec51-b7edf3224227"
      },
      "source": [
        "import numpy as np\n",
        "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NST1D0ZnXih"
      },
      "source": [
        "## Visualizing learned embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksUMN3FRoKy7",
        "outputId": "4666860e-67db-4f7e-e3fe-6b4ebb2efaf1"
      },
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUosxSVIoZXZ",
        "outputId": "b742a85e-c88d-45eb-deae-1162eb18934c"
      },
      "source": [
        "# Model 1 summary\n",
        "model_1.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4as6gmz_ohgI",
        "outputId": "7567bcc0-9fe6-4fce-a876-f68c778b1223"
      },
      "source": [
        "# Get the weight matrix of embedding layer\n",
        "# (these are the numerical representations of each token in our training data)\n",
        "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
        "print(embed_weights.shape)  # same size as vocab size and embedding dim (output_dim of our embedding layer)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tmbaxo6Hplfk"
      },
      "source": [
        "Now we've got the embedding matrix our model has learned to represent our tokens, let's see how we can visualize it.\n",
        "\n",
        "To do so, TensorFlow has a handy tool called projector: https://projector.tensorflow.org/\n",
        "\n",
        "And TensorFlow also has an incredible guide on word embeddings themselves: https://www.tensorflow.org/text/guide/word_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOU0fmFRo3w_"
      },
      "source": [
        "# # Create embedding files (we got this from TensorFlow's word embeddings documentation)\n",
        "# import io\n",
        "# out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "# out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "# for index, word in enumerate(words_in_vocab):\n",
        "#   if index == 0:\n",
        "#     continue  # skip 0, it's padding.\n",
        "#   vec = embed_weights[index]\n",
        "#   out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "#   out_m.write(word + \"\\n\")\n",
        "# out_v.close()\n",
        "# out_m.close()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7H8sTufpeWi"
      },
      "source": [
        "#  # Download files from colab to projector\n",
        "#  try:\n",
        "#   from google.colab import files\n",
        "#   files.download('vectors.tsv')\n",
        "#   files.download('metadata.tsv')\n",
        "# except Exception:\n",
        "#   pass"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAMhF2for5pr"
      },
      "source": [
        "## Recurrent Neural Networks (RNN's)\n",
        "\n",
        "RNN's are useful for sequence data.\n",
        "\n",
        "The premise of a recurrent neural network is to use the respresentation of a previous input to aid the representation of  a later input.\n",
        "\n",
        "> **📖 Resources:**If you want an overview of the internals of a recurrent neural network, see the following:\n",
        "- MIT's sequence modelling lecture https://youtu.be/qjrad0V0uJE\n",
        "- Chris Olah's intro to LSTMs: https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
        "- Andrej Karpathy's http://karpathy.github.io/2015/05/21/rnn-effectiveness/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M3nDVeXK-te"
      },
      "source": [
        "### Model 2: LSTM\n",
        "\n",
        "LSTM = Long short term memory (one of the most popular LSTM cells)\n",
        "\n",
        "Our structure of an RNN typically looks like this#\n",
        "\n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers (RNNs/dense) -> Output (label probability)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh4erdpcPXMO"
      },
      "source": [
        "# Create an LSTM model\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# print(x.shape)\n",
        "x = layers.LSTM(units=64, return_sequences=True)(x) # when you're stacking RNN cells togather, you need to return_seqeunces=True\n",
        "# print(x.shape)\n",
        "x = layers.LSTM(64)(x)\n",
        "# print(x.shape)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "# print(x.shape)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddffl1cUQ3Bw"
      },
      "source": [
        "# Compile the model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMrs8J8SU_-d",
        "outputId": "200c6d46-e74d-4c41-cf64-67c400502747"
      },
      "source": [
        "# Fit the model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"model_2_LSTM\")])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20211115-131005\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 11s 20ms/step - loss: 0.2214 - accuracy: 0.9266 - val_loss: 0.5061 - val_accuracy: 0.7795\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.1585 - accuracy: 0.9428 - val_loss: 0.5767 - val_accuracy: 0.7835\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.1290 - accuracy: 0.9529 - val_loss: 0.6993 - val_accuracy: 0.7848\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.1074 - accuracy: 0.9604 - val_loss: 0.7988 - val_accuracy: 0.7585\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0872 - accuracy: 0.9648 - val_loss: 1.0154 - val_accuracy: 0.7795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC6bIKfVVjSZ",
        "outputId": "736697e9-1dbb-4fa4-8608-2ed95844a285"
      },
      "source": [
        "# Make predictions with LSTM model\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.3559477e-02],\n",
              "       [7.9249501e-01],\n",
              "       [9.9997020e-01],\n",
              "       [1.7130667e-01],\n",
              "       [7.5704220e-04],\n",
              "       [9.9980634e-01],\n",
              "       [9.9387819e-01],\n",
              "       [9.9998641e-01],\n",
              "       [9.9996352e-01],\n",
              "       [7.6371282e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy6GKmuYV3VW",
        "outputId": "80bb4aa1-42eb-4e37-e62e-df4f20a791b2"
      },
      "source": [
        "# Convert model 2 pred probs to labels\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddMgVUynWH5M",
        "outputId": "f0bc57a0-14d3-44a6-939e-206a5d2efcd7"
      },
      "source": [
        "# Calculate model_2 results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.95275590551181,\n",
              " 'f1': 0.7790235518023306,\n",
              " 'precision': 0.779213392666068,\n",
              " 'recall': 0.7795275590551181}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wNbSdpyWbe1"
      },
      "source": [
        "### Model 3: GRU\n",
        "\n",
        "Another popular and effective RNN component is the GRU or gated recurrent unit.\n",
        "\n",
        "The GRU cell has similar features to an LSTM cell but has less parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C1V8a1ZXUyL"
      },
      "source": [
        "# Build an RNN using the GRU cell\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GRU(64)(x)\n",
        "# x = layers.GRU(64, return_sequences=True)(x)  # if you're stacking RNN cells togather, you need to return_seqeunces=True\n",
        "# x = layers.LSTM(42, return_sequences=True)(x)\n",
        "# x = layers.GRU(99)(x)\n",
        "# x = layers.Dense(64, activation=\"sigmoid\")(x)\n",
        "# x = layers.GlobalAveragePooling1D()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clIuCFdRby_U",
        "outputId": "278912e4-5543-404c-938b-392b16a53871"
      },
      "source": [
        "# Get summary\n",
        "model_3.summary()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFF3eYlcboi6"
      },
      "source": [
        "# Compile the model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1LGN5G3cH5X",
        "outputId": "a3e13a60-b9a2-4a80-b922-c85415c48a3d"
      },
      "source": [
        "# Fit the model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"model_3_GRU\")])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_GRU/20211115-131031\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 13ms/step - loss: 0.1616 - accuracy: 0.9350 - val_loss: 0.7582 - val_accuracy: 0.7717\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0862 - accuracy: 0.9673 - val_loss: 0.7523 - val_accuracy: 0.7730\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0695 - accuracy: 0.9729 - val_loss: 0.9331 - val_accuracy: 0.7743\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.0611 - accuracy: 0.9752 - val_loss: 0.9435 - val_accuracy: 0.7703\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0542 - accuracy: 0.9766 - val_loss: 1.0836 - val_accuracy: 0.7782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnwb-dhJck9A",
        "outputId": "b993a6fc-a64e-4363-bb50-a516cdeed068"
      },
      "source": [
        "# Make predictions with LSTM model\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs[:10]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.5320185e-02],\n",
              "       [6.9793308e-01],\n",
              "       [9.9979740e-01],\n",
              "       [1.0802479e-01],\n",
              "       [1.7232606e-04],\n",
              "       [9.9968612e-01],\n",
              "       [8.7652791e-01],\n",
              "       [9.9991810e-01],\n",
              "       [9.9985874e-01],\n",
              "       [6.8518203e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIyadG2HcuPu",
        "outputId": "db6bd696-7fb0-4a87-8fcc-4f7669af5a13"
      },
      "source": [
        "# Convert model 3 pred probs to labels\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvMJH5NWc6_a",
        "outputId": "99647d5e-63fb-4f8f-d3c5-a2927a5ed060"
      },
      "source": [
        "# Calculate model_3 results\n",
        "model_3_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.82152230971128,\n",
              " 'f1': 0.7766208088282468,\n",
              " 'precision': 0.7791991586469295,\n",
              " 'recall': 0.7782152230971129}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqKP7R7hc_rn"
      },
      "source": [
        "### Model 4: Bidirectional RNN\n",
        "\n",
        "Normal RNN's go from left to right (just like you'd read an English sentence) however, a bidirectional RNN goes from left to right as well as right to left."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bniPPBRFenmX"
      },
      "source": [
        "# Build a bidirectional RNN\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs,outputs, name=\"model_4_bidirectional\")"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChY17UnHfw32",
        "outputId": "9ac10b74-e749-4cf7-fff0-61f8368d6717"
      },
      "source": [
        "# Get a summary\n",
        "model_4.summary()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_bidirectional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ED25Jx7f9gg"
      },
      "source": [
        "# Compile the model\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8Uh0ruqgnfz",
        "outputId": "cd59263e-5069-408e-d2da-e66bd2371272"
      },
      "source": [
        "# Fit the model\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"model_4_Bidirectional\")])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_Bidirectional/20211115-131046\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 20ms/step - loss: 0.1076 - accuracy: 0.9650 - val_loss: 1.0892 - val_accuracy: 0.7612\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0512 - accuracy: 0.9771 - val_loss: 1.1828 - val_accuracy: 0.7625\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0471 - accuracy: 0.9796 - val_loss: 1.1778 - val_accuracy: 0.7677\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0499 - accuracy: 0.9783 - val_loss: 1.3340 - val_accuracy: 0.7651\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0385 - accuracy: 0.9803 - val_loss: 1.4619 - val_accuracy: 0.7493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3zwsQSjgr5P",
        "outputId": "24cfa1f3-6846-49c8-d5d5-cb650fceeb2f"
      },
      "source": [
        "# Make predictions with LSTM model\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.2919606e-01],\n",
              "       [6.9013143e-01],\n",
              "       [9.9997556e-01],\n",
              "       [2.3729908e-01],\n",
              "       [1.8338327e-05],\n",
              "       [9.9983597e-01],\n",
              "       [9.8102665e-01],\n",
              "       [9.9998856e-01],\n",
              "       [9.9997556e-01],\n",
              "       [9.8110604e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdvdLsSFgwra",
        "outputId": "71fb24ba-ed41-4745-f6a4-3b4941a4c625"
      },
      "source": [
        "# Convert model 4 pred probs to labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2mG9bWfg2qo",
        "outputId": "ff5340dc-6cb9-4b80-edf6-e0e716b4a12c"
      },
      "source": [
        "# Calculate model_4 results\n",
        "model_4_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_4_preds)\n",
        "model_4_results"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 74.93438320209974,\n",
              " 'f1': 0.7485447240178604,\n",
              " 'precision': 0.7488957031272704,\n",
              " 'recall': 0.7493438320209974}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eh8EHqA3g9Pf"
      },
      "source": [
        "## Convolution Neural Networks for Text (and other types of sequences)\n",
        "\n",
        "We've used CNNs for images but images are typically 2D (height x width) ... however, our text data is 1D.\n",
        "\n",
        "Previously we've used Conv2D but now we are going to use Conv1D.\n",
        "\n",
        "The typical structure of a Conv1D for sequences (in our case, text):\n",
        "\n",
        "```\n",
        "Inputs (text) -> Tokenization -> Embedding -> Layer(s) (typically Conv1D + pooling) -> Outputs (Class probability)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bDrjoPqgu6Z"
      },
      "source": [
        "### Model 5: Conv1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DjXVDs3hti4",
        "outputId": "05744ea0-8add-4130-dd4c-03ccb82d2f49"
      },
      "source": [
        "# Test out our embedding layer, Conv1D layer and max pooling layer\n",
        "embedding_test = embedding(text_vectorizer([\"this is a sentence\"])) # turn target sequence into embedding\n",
        "conv_1d = layers.Conv1D(filters=32,\n",
        "                        kernel_size=5,  # this is also referred to as an ngram of 5 (meaning it looks at 5 words at a time)\n",
        "                        activation=\"relu\",\n",
        "                        padding=\"valid\")  # default = \"valid\", the output is smaller than the input shape, \"same\" means output is same shape as input\n",
        "\n",
        "conv1d_output = conv_1d(embedding_test) # pass test embedding through conv1D layer\n",
        "max_pool = layers.GlobalAveragePooling1D()\n",
        "max_pool_output = max_pool(conv1d_output) # equivalent to \"get the most important one feature\" or \"get the feature with the highest value\"\n",
        "\n",
        "embedding_test.shape, conv1d_output.shape, max_pool_output.shape"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca_Ya6ealEs2"
      },
      "source": [
        "# embedding_test"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiNo6zTYnRbN"
      },
      "source": [
        "# conv1d_output"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFso9vzSnV30"
      },
      "source": [
        "# max_pool_output"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k_vCa_wns1F",
        "outputId": "37ecd16a-b29e-4ee4-94b1-84ad9c469691"
      },
      "source": [
        "# Create 1-dimension convolutional neural layer to model sequences\n",
        "from tensorflow.keras import layers\n",
        "input = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(filters=64, kernel_size=5, strides=1, activation=\"relu\", padding=\"valid\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
        "\n",
        "# Compile Conv1D\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get summary of Conv1D model\n",
        "model_5.summary()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 11, 64)            41024     \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 64)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRd5UpkHp0sv",
        "outputId": "fa90b8cb-a967-46ae-ec18-af6a00dc6bcf"
      },
      "source": [
        "# Fit the Conv1D model\n",
        "model_5.fit(train_sentences,\n",
        "            train_labels,\n",
        "            epochs=5,\n",
        "            validation_data=(val_sentences, val_labels),\n",
        "                             callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                    \"Conv1D\")])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20211115-131132\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 9ms/step - loss: 0.1242 - accuracy: 0.9596 - val_loss: 0.8996 - val_accuracy: 0.7690\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0742 - accuracy: 0.9731 - val_loss: 1.0390 - val_accuracy: 0.7664\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0616 - accuracy: 0.9745 - val_loss: 1.1468 - val_accuracy: 0.7585\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.0554 - accuracy: 0.9788 - val_loss: 1.1832 - val_accuracy: 0.7559\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0548 - accuracy: 0.9774 - val_loss: 1.1999 - val_accuracy: 0.7598\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4e94a006d0>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJqDs7bVqb9R",
        "outputId": "e2169ffb-7e47-4fad-fac5-84f7ba7aa794"
      },
      "source": [
        "# Make some predictions with our Conv1D model\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.0542126e-01],\n",
              "       [9.5308864e-01],\n",
              "       [9.9988937e-01],\n",
              "       [6.1505888e-02],\n",
              "       [5.1331818e-07],\n",
              "       [9.9329245e-01],\n",
              "       [9.7772938e-01],\n",
              "       [9.9998033e-01],\n",
              "       [9.9999928e-01],\n",
              "       [7.0028532e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21fkzajZq6CV",
        "outputId": "8cec8c22-0140-4e40-a7ad-5d874e1581c3"
      },
      "source": [
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIvkz1iErBG2",
        "outputId": "19831884-6138-4abe-c323-65c2c5d4b442"
      },
      "source": [
        "# Evaluate model 5 predictions\n",
        "model_5_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.98425196850394,\n",
              " 'f1': 0.7586850461611226,\n",
              " 'precision': 0.7597625353264251,\n",
              " 'recall': 0.7598425196850394}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4p1ARcZrLNM",
        "outputId": "abd6e299-99e0-4d82-ca23-e8826d1d7149"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUOfeE8PrTPl"
      },
      "source": [
        "## Model 6: TensorFlow Hub Pretrained Sentence Encoder\n",
        "\n",
        "Now we've built a few of our own models, let's try and use transfer learning for NLP. specifically using TensorFlow Hub's Universal Entence Encoder https://tfhub.dev/google/universal-sentence-encoder/4\n",
        "\n",
        "See how the USE was created here: https://arxiv.org/abs/1803.11175"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vyErqIMvuxIQ",
        "outputId": "5b933316-23ea-44c3-c0c1-67d941346d8d"
      },
      "source": [
        "sample_sentence"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"There's a flood in my street!\""
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olh9dRXmr-ky",
        "outputId": "5bcd3c42-505a-410c-ec09-6d984d332a99"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "embed_samples = embed([sample_sentence,\n",
        "                       \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
        "print(embed_samples[0][:50])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.01157024  0.0248591   0.0287805  -0.01271502  0.03971543  0.08827759\n",
            "  0.02680986  0.05589837 -0.01068731 -0.0059729   0.00639324 -0.01819523\n",
            "  0.00030817  0.09105891  0.05874644 -0.03180627  0.01512476 -0.05162928\n",
            "  0.00991369 -0.06865346 -0.04209306  0.0267898   0.03011008  0.00321069\n",
            " -0.00337969 -0.04787359  0.02266718 -0.00985924 -0.04063614 -0.01292095\n",
            " -0.04666384  0.056303   -0.03949255  0.00517685  0.02495828 -0.07014439\n",
            "  0.02871508  0.04947682 -0.00633971 -0.08960191  0.02807117 -0.00808362\n",
            " -0.01360601  0.05998649 -0.10361786 -0.05195372  0.00232955 -0.02332528\n",
            " -0.03758105  0.0332773 ], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7iPAGIXuV7V",
        "outputId": "660aa702-07e0-4b9a-b8a1-2f32449a50e4"
      },
      "source": [
        "embed_samples[0].shape"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDvchuASuruE"
      },
      "source": [
        "# Create a Keras Layer using the USE pretrained layer from tensorflow hub\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[],\n",
        "                                        dtype=tf.string,\n",
        "                                        trainable=False,\n",
        "                                        name=\"USE\")"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxHUiXvvwD3g",
        "outputId": "363eb1fe-7024-4c80-f64e-3d641aff754c"
      },
      "source": [
        "# Create model using Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "                               sentence_encoder_layer,\n",
        "                               layers.Dense(64, activation=\"relu\"),\n",
        "                               layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")\n",
        "], name=\"Model_6_USE\")\n",
        "\n",
        "# Compile the model\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get summary\n",
        "model_6.summary()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyrARBgrw4UU",
        "outputId": "6cb7a15d-c546-473d-a5c2-7b242cb47d2e"
      },
      "source": [
        "# Train a classifier on top of the USE pretrained embeddings\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"tf_hub_sentence_encoder\")])"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20211115-131208\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 23ms/step - loss: 0.5033 - accuracy: 0.7869 - val_loss: 0.4475 - val_accuracy: 0.7979\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.4147 - accuracy: 0.8145 - val_loss: 0.4394 - val_accuracy: 0.8123\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.4018 - accuracy: 0.8206 - val_loss: 0.4356 - val_accuracy: 0.8097\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 5s 21ms/step - loss: 0.3932 - accuracy: 0.8246 - val_loss: 0.4328 - val_accuracy: 0.8136\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 5s 21ms/step - loss: 0.3859 - accuracy: 0.8272 - val_loss: 0.4290 - val_accuracy: 0.8084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM_c8RtOxZpG",
        "outputId": "481b9a10-7558-4c33-eb30-8bc9c0b25f4b"
      },
      "source": [
        "# Make predictions with USE TF Hub model\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.24064587],\n",
              "       [0.7944369 ],\n",
              "       [0.98945075],\n",
              "       [0.20122835],\n",
              "       [0.7819531 ],\n",
              "       [0.84364104],\n",
              "       [0.9845408 ],\n",
              "       [0.98437   ],\n",
              "       [0.9602138 ],\n",
              "       [0.10905415]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnzGXubDxvGT",
        "outputId": "ff81e8ad-c243-45ef-8b08-12c79b96b97a"
      },
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b382YlFWx7Jr",
        "outputId": "cd9ce002-f616-4bad-978e-e4c95f836891"
      },
      "source": [
        "# Calculate model 6 performance metrics\n",
        "model_6_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_6_preds)\n",
        "model_6_results"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 80.83989501312337,\n",
              " 'f1': 0.8077514730278195,\n",
              " 'precision': 0.8084704501710461,\n",
              " 'recall': 0.8083989501312336}"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KgNUhv2yLgt",
        "outputId": "e13152f3-d80f-4379-e6be-f9788d5c9148"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCR3MXxPyO5k"
      },
      "source": [
        "## Model 7: TF Hub pretrained USE but with 10% of training data\n",
        "\n",
        "Transfer Learning really helps when you don't have a large dataset.\n",
        "\n",
        "To see how our model performs on a smaller dataset, let's replicate `model_6` excepth we'll train it on 10% of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_aojKDbCrzS"
      },
      "source": [
        "# ## NOTE: Making data splts likebelow leads to data leakage (model_7 trained on 10% data, outperforms model_6 trained on 100% data)\n",
        "# ## DO NOT MAKE DATA SPLITS WHICH LEAK DATA FROM VALIDATION/TEST SETS INTO TRAINING SET\n",
        "\n",
        "# # Create subsets of 10% of the training data\n",
        "# train_10_percent = train_df_shuffled[[\"text\", \"target\"]].sample(frac=0.1, random_state=42)\n",
        "# train_sentences_10_percent = train_10_percent[\"text\"].to_list()\n",
        "# train_labels_10_percent = train_10_percent[\"target\"].to_list()\n",
        "# len(train_sentences_10_percent), len(train_labels_10_percent)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqhnJGpmLt_h"
      },
      "source": [
        "> **🔑 Note:** Be *very* careful when creating training/val/test splits that you don't leak data across the datasets, otherwise your model evaluation metrics will be wrong. If something looks too good to be true (a model on 10% of data outperforming a same model trained on 100% of data). Trust your gut and go back through to find where the error may lie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdJ0JC-kKTbi"
      },
      "source": [
        "# Making a better dataset split (no data leakage)\n",
        "train_10_percent_split = int(0.1 * len(train_sentences))\n",
        "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
        "train_labels_10_percent = train_labels[:train_10_percent_split]"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doss7xXlLIMZ",
        "outputId": "0ec6effd-59a1-4681-ab98-3c8b081bd20c"
      },
      "source": [
        "# Check the number of each label in the new created data\n",
        "pd.Series(np.array(train_labels_10_percent)).value_counts()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    406\n",
              "1    279\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "9hX0vwbCDlAH",
        "outputId": "fdac4827-25e2-49ae-c83b-9361e6e9ec5e"
      },
      "source": [
        "# Check the number of targets in our subset of data\n",
        "train_sentences_10_percent[\"target\"].value_counts()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-77ffb7696957>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check the number of targets in our subset of data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_sentences_10_percent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTlvr_uUEpCP"
      },
      "source": [
        "To recreate a model the same as a previous model you've created you can use the `tf.keras.models.clone_model()` method. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfDZw0YxEjxY",
        "outputId": "1873f945-dab1-467a-e685-ff7c3c82eef1"
      },
      "source": [
        "# model_7 = tf.keras.models.clone_model(model_6)\n",
        "# Create model using Sequential API\n",
        "model_7 = tf.keras.Sequential([\n",
        "                               sentence_encoder_layer,\n",
        "                               layers.Dense(64, activation=\"relu\"),\n",
        "                               layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")\n",
        "], name=\"Model_7_USE\")\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get summary\n",
        "model_7.summary()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Model_7_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8JxgtlpECg4",
        "outputId": "5b3bc362-5c44-4b4c-e6aa-4ab982a64eca"
      },
      "source": [
        "# Train a classifier on top of the USE pretrained embeddings\n",
        "model_7_history = model_7.fit(train_sentences_10_percent,\n",
        "                              train_labels_10_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"tf_hub_sentence_encoder_10_percent\")])"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder_10_percent/20211115-131426\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 3s 72ms/step - loss: 0.6753 - accuracy: 0.6803 - val_loss: 0.6546 - val_accuracy: 0.7375\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 1s 49ms/step - loss: 0.6132 - accuracy: 0.7985 - val_loss: 0.6000 - val_accuracy: 0.7717\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 1s 49ms/step - loss: 0.5420 - accuracy: 0.8204 - val_loss: 0.5459 - val_accuracy: 0.7690\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 1s 49ms/step - loss: 0.4784 - accuracy: 0.8307 - val_loss: 0.5108 - val_accuracy: 0.7782\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 1s 37ms/step - loss: 0.4345 - accuracy: 0.8307 - val_loss: 0.4926 - val_accuracy: 0.7756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrkHKHjkEh6Q",
        "outputId": "ae594535-4dd8-488f-f07e-826c277e2cfa"
      },
      "source": [
        "# Make predictions with 10% USE TF Hub model\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.23620038],\n",
              "       [0.6091783 ],\n",
              "       [0.90677017],\n",
              "       [0.38610035],\n",
              "       [0.5586967 ],\n",
              "       [0.6852183 ],\n",
              "       [0.86610276],\n",
              "       [0.79553217],\n",
              "       [0.83122355],\n",
              "       [0.15478541]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZRRLmvEFf3l",
        "outputId": "6903359f-1012-4777-9c35-27abaeafb784"
      },
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Mj_WZ-GFioo",
        "outputId": "0eecee7b-d2e8-4177-ecd9-079dab67b485"
      },
      "source": [
        "# Calculate model 6 performance metrics\n",
        "model_7_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_7_preds)\n",
        "model_7_results"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.55905511811024,\n",
              " 'f1': 0.7739772681043204,\n",
              " 'precision': 0.7765218346613636,\n",
              " 'recall': 0.7755905511811023}"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ob3_mA6gF6ZN",
        "outputId": "7925be79-c808-45fd-9bf9-bd3331c92a12"
      },
      "source": [
        "model_6_results"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 80.83989501312337,\n",
              " 'f1': 0.8077514730278195,\n",
              " 'precision': 0.8084704501710461,\n",
              " 'recall': 0.8083989501312336}"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-_d7C1bIMZ4"
      },
      "source": [
        "## Comparing the performance of each our models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "tzrTZqB3MsBb",
        "outputId": "0feb2635-3a9b-4fcc-c05b-5bd415641875"
      },
      "source": [
        "# Combine model results into a dataFrame\n",
        "all_model_results = pd.DataFrame({\"0_baseline\": baseline_results,\n",
        "                                 \"1_simple_dense\": model_1_results,\n",
        "                                 \"2_LSTM\": model_2_results,\n",
        "                                 \"3_GRU\": model_3_results,\n",
        "                                 \"4_Bidirectional\": model_4_results,\n",
        "                                 \"5_CONV1D\": model_5_results,\n",
        "                                 \"6_TF_HUB_USE_Encoder\": model_6_results,\n",
        "                                 \"7_TF_HUB_USE_Encoder_on_10%_of_data\": model_7_results})\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_baseline</th>\n",
              "      <td>79.265092</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_simple_dense</th>\n",
              "      <td>78.871391</td>\n",
              "      <td>0.794369</td>\n",
              "      <td>0.788714</td>\n",
              "      <td>0.785521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_LSTM</th>\n",
              "      <td>77.952756</td>\n",
              "      <td>0.779213</td>\n",
              "      <td>0.779528</td>\n",
              "      <td>0.779024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_GRU</th>\n",
              "      <td>77.821522</td>\n",
              "      <td>0.779199</td>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.776621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_Bidirectional</th>\n",
              "      <td>74.934383</td>\n",
              "      <td>0.748896</td>\n",
              "      <td>0.749344</td>\n",
              "      <td>0.748545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_CONV1D</th>\n",
              "      <td>75.984252</td>\n",
              "      <td>0.759763</td>\n",
              "      <td>0.759843</td>\n",
              "      <td>0.758685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_TF_HUB_USE_Encoder</th>\n",
              "      <td>80.839895</td>\n",
              "      <td>0.808470</td>\n",
              "      <td>0.808399</td>\n",
              "      <td>0.807751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_TF_HUB_USE_Encoder_on_10%_of_data</th>\n",
              "      <td>77.559055</td>\n",
              "      <td>0.776522</td>\n",
              "      <td>0.775591</td>\n",
              "      <td>0.773977</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      accuracy  precision    recall        f1\n",
              "0_baseline                           79.265092   0.811139  0.792651  0.786219\n",
              "1_simple_dense                       78.871391   0.794369  0.788714  0.785521\n",
              "2_LSTM                               77.952756   0.779213  0.779528  0.779024\n",
              "3_GRU                                77.821522   0.779199  0.778215  0.776621\n",
              "4_Bidirectional                      74.934383   0.748896  0.749344  0.748545\n",
              "5_CONV1D                             75.984252   0.759763  0.759843  0.758685\n",
              "6_TF_HUB_USE_Encoder                 80.839895   0.808470  0.808399  0.807751\n",
              "7_TF_HUB_USE_Encoder_on_10%_of_data  77.559055   0.776522  0.775591  0.773977"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "JePObV8rNjK-",
        "outputId": "1416203d-e456-432f-9f8c-79ad7f6a29b0"
      },
      "source": [
        "# # Reduce the accuracy to the same scale as other metrics\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100\n",
        "all_model_results"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_baseline</th>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_simple_dense</th>\n",
              "      <td>0.788714</td>\n",
              "      <td>0.794369</td>\n",
              "      <td>0.788714</td>\n",
              "      <td>0.785521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_LSTM</th>\n",
              "      <td>0.779528</td>\n",
              "      <td>0.779213</td>\n",
              "      <td>0.779528</td>\n",
              "      <td>0.779024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_GRU</th>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.779199</td>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.776621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_Bidirectional</th>\n",
              "      <td>0.749344</td>\n",
              "      <td>0.748896</td>\n",
              "      <td>0.749344</td>\n",
              "      <td>0.748545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_CONV1D</th>\n",
              "      <td>0.759843</td>\n",
              "      <td>0.759763</td>\n",
              "      <td>0.759843</td>\n",
              "      <td>0.758685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_TF_HUB_USE_Encoder</th>\n",
              "      <td>0.808399</td>\n",
              "      <td>0.808470</td>\n",
              "      <td>0.808399</td>\n",
              "      <td>0.807751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_TF_HUB_USE_Encoder_on_10%_of_data</th>\n",
              "      <td>0.775591</td>\n",
              "      <td>0.776522</td>\n",
              "      <td>0.775591</td>\n",
              "      <td>0.773977</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     accuracy  precision    recall        f1\n",
              "0_baseline                           0.792651   0.811139  0.792651  0.786219\n",
              "1_simple_dense                       0.788714   0.794369  0.788714  0.785521\n",
              "2_LSTM                               0.779528   0.779213  0.779528  0.779024\n",
              "3_GRU                                0.778215   0.779199  0.778215  0.776621\n",
              "4_Bidirectional                      0.749344   0.748896  0.749344  0.748545\n",
              "5_CONV1D                             0.759843   0.759763  0.759843  0.758685\n",
              "6_TF_HUB_USE_Encoder                 0.808399   0.808470  0.808399  0.807751\n",
              "7_TF_HUB_USE_Encoder_on_10%_of_data  0.775591   0.776522  0.775591  0.773977"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "7l1JmL5zOoAD",
        "outputId": "6cef2f32-a91c-41d2-d1b0-125f96d2c18f"
      },
      "source": [
        "# Plot and compare all of the model results\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10,7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "b4INP50PPUEE",
        "outputId": "028860c6-ddf2-4c6c-8638-84fe0e3f13f8"
      },
      "source": [
        "# Sort the model results by f1-score\n",
        "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10,7))"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4e36260690>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e2dY4elRjM9"
      },
      "source": [
        "## Uploading our model training logs to TensorBoard.dev\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlDWEJsLSKm8"
      },
      "source": [
        "# View TensorBoad logs of transfer learning modelling experiments (plus all of our other models)\n",
        "# Upload TensorBoard dev records\n",
        "!tensorboard dev upload --logdir ./model_logs/ \\\n",
        "  --name \"NLP Modeling Experiments\" \\\n",
        "  --description \"Comparing multiple different types of model architectures on the Kaggle Tweets text classification dataset\" \\\n",
        "  --one_shot # exit the uploader once uploading is finished"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXb_li9oTAe2"
      },
      "source": [
        "## Saving and loading trained model\n",
        "\n",
        "There are two main formats to save a model to in TensorFlow:\n",
        "1. The HDF5 format\n",
        "2. The `SavedModel` format (this is the default when using TensorFlow)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLune8h4UplF"
      },
      "source": [
        "# Save TF Hub Sentence Encoder model to HDF5 format\n",
        "model_6.save(\"model_6.h5\")"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyrL3-tAU3FV"
      },
      "source": [
        "# Load model with custom hub layer (required HDF5 format)\n",
        "loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\",\n",
        "                                            custom_objects={\"KerasLayer\": hub.KerasLayer})"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0i8ys0NPVaop",
        "outputId": "9b79696d-d78c-4fc2-c8d5-032fab358ef4"
      },
      "source": [
        "# How does our loaded model perform\n",
        "loaded_model_6.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 17ms/step - loss: 0.4290 - accuracy: 0.8084\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4289577901363373, 0.808398962020874]"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgUeYXIbWDPw"
      },
      "source": [
        "Now let's save to the `SavedModel` formate ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yVTUegMVrkL",
        "outputId": "f7a640ac-106c-4e87-8f12-7306cf10e227"
      },
      "source": [
        "# Save TF Hub Sentence Encoder SavedModel to model format (default)\n",
        "model_6.save(\"model_6.model\")"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: model_6.model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: model_6.model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAFm8t8TV6RL"
      },
      "source": [
        "# Load model with custom hub layer (required HDF5 format)\n",
        "loaded_model_6_SavedModel_format = tf.keras.models.load_model(\"model_6.model\")"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zXSzCS9WTgS",
        "outputId": "aa046262-b9d8-433e-d00a-abc61aa4a0ac"
      },
      "source": [
        "# Evaluate model in SavedModel format\n",
        "loaded_model_6_SavedModel_format.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 16ms/step - loss: 0.4290 - accuracy: 0.8084\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4289577901363373, 0.808398962020874]"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bF9ZR8xNWeRT"
      },
      "source": [
        "## Finding the most wrong examples\n",
        "\n",
        "* If our best model still isn't perfect, what examples is it getting wrong?\n",
        "* And of these wrong examples which one is it getting *most* wrong (those with prediction probabilities closest to the opposite class)\n",
        "\n",
        "For example if a sample should have a label of 0 but our model predicts a prediction probability of 0.999 (really close to 1) and vice versa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRSjwOVUa2D1",
        "outputId": "0ee57356-a391-40d1-a181-4972e5106308"
      },
      "source": [
        "# Download a pretrained model\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
        "!unzip 08_model_6_USE_feature_extractor.zip"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-15 13:15:23--  https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.202.128, 74.125.69.128, 64.233.183.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.202.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 960779165 (916M) [application/zip]\n",
            "Saving to: ‘08_model_6_USE_feature_extractor.zip’\n",
            "\n",
            "08_model_6_USE_feat 100%[===================>] 916.27M  42.5MB/s    in 8.7s    \n",
            "\n",
            "2021-11-15 13:15:32 (105 MB/s) - ‘08_model_6_USE_feature_extractor.zip’ saved [960779165/960779165]\n",
            "\n",
            "Archive:  08_model_6_USE_feature_extractor.zip\n",
            "   creating: 08_model_6_USE_feature_extractor/\n",
            "   creating: 08_model_6_USE_feature_extractor/assets/\n",
            "   creating: 08_model_6_USE_feature_extractor/variables/\n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.data-00000-of-00001  \n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.index  \n",
            "  inflating: 08_model_6_USE_feature_extractor/saved_model.pb  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vxopDvEbVQx",
        "outputId": "86a8f5b5-5938-4fdb-f2d3-d0f841b696b2"
      },
      "source": [
        "# Import previously trained model from Google Storage\n",
        "model_6_pretrained = tf.keras.models.load_model(\"08_model_6_USE_feature_extractor\")\n",
        "model_6_pretrained.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 18ms/step - loss: 0.4272 - accuracy: 0.8163\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.42723119258880615, 0.8162729740142822]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IK_SHvtEbwaP",
        "outputId": "fa604175-ff90-4899-947f-18c6a0176ab1"
      },
      "source": [
        "# Make predictions with the loaded model from GS\n",
        "model_6_pretrained_pred_probs = model_6_pretrained.predict(val_sentences)\n",
        "model_6_pretrained_preds = tf.squeeze(tf.round(model_6_pretrained_pred_probs))\n",
        "model_6_pretrained_preds[:10] # these should in label format"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "AEURRNT8Z3kF",
        "outputId": "a04f73fd-5634-42e3-9cac-23f8e227d9ae"
      },
      "source": [
        "# Create DataFrame with validation sentences and best performing model predictions labels and probabilities\n",
        "val_df = pd.DataFrame({\"text\": val_sentences,\n",
        "                      \"target\": val_labels,\n",
        "                      \"pred\": model_6_pretrained_preds,\n",
        "                      \"pred_prob\": tf.squeeze(model_6_pretrained_pred_probs)})\n",
        "val_df.head()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.159757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.747162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.988749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@camilacabello97 Internally and externally scr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.196229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Radiation emergency #preparedness starts with ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.707808</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target  pred  pred_prob\n",
              "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.159757\n",
              "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.747162\n",
              "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.988749\n",
              "3  @camilacabello97 Internally and externally scr...       1   0.0   0.196229\n",
              "4  Radiation emergency #preparedness starts with ...       1   1.0   0.707808"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "RkorAMEqcwap",
        "outputId": "02411f6f-27b4-44fc-99b0-98ec63adbe03"
      },
      "source": [
        "# Find the wrong predictions and sort by prediction probabilities\n",
        "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\",ascending=False)\n",
        "most_wrong[:10] # these are false positives"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.910196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>FedEx will no longer transport bioterror patho...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.876982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>@noah_anyname That's where the concentration c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.852300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.835454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.827213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.814816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.810840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.803122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>@freefromwolves GodsLove &amp;amp; #thankU brother...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.766901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>Air Group is here to the rescue! We have 24/7 ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.766625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  target  pred  pred_prob\n",
              "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   0.910196\n",
              "759  FedEx will no longer transport bioterror patho...       0   1.0   0.876982\n",
              "628  @noah_anyname That's where the concentration c...       0   1.0   0.852300\n",
              "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0   1.0   0.835454\n",
              "251  @AshGhebranious civil rights continued in the ...       0   1.0   0.827213\n",
              "393  @SonofLiberty357 all illuminated by the bright...       0   1.0   0.814816\n",
              "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0   1.0   0.810840\n",
              "49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   0.803122\n",
              "119  @freefromwolves GodsLove &amp; #thankU brother...       0   1.0   0.766901\n",
              "344  Air Group is here to the rescue! We have 24/7 ...       0   1.0   0.766625"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JV0_KjYdo67"
      },
      "source": [
        "Let's remind ourselves of the target labels\n",
        "* 0 = not disaster\n",
        "* 1 = disaster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "u9vmw1Mzd28_",
        "outputId": "12ba2a96-c11e-47c4-ac15-61defc9c9818"
      },
      "source": [
        "most_wrong.tail() # these are false negatives"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>@SoonerMagic_ I mean I'm a fan but I don't nee...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>I get to smoke my shit in peace</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Why are you deluged with low self-image? Take ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>Reddit Will Now QuarantineÛ_ http://t.co/pkUA...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Ron &amp;amp; Fez - Dave's High School Crush https...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.037186</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  target  pred  pred_prob\n",
              "411  @SoonerMagic_ I mean I'm a fan but I don't nee...       1   0.0   0.043918\n",
              "233                    I get to smoke my shit in peace       1   0.0   0.042087\n",
              "38   Why are you deluged with low self-image? Take ...       1   0.0   0.038998\n",
              "244  Reddit Will Now QuarantineÛ_ http://t.co/pkUA...       1   0.0   0.038949\n",
              "23   Ron &amp; Fez - Dave's High School Crush https...       1   0.0   0.037186"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Po-SSaId9cy",
        "outputId": "b289d8bf-6470-464e-bfa8-3539bcf3df26"
      },
      "source": [
        "# Check the false positives (model predicted 1 when should've been 0)\n",
        "for row in most_wrong[:10].itertuples():\n",
        "  _, text, target, pred, pred_prob = row\n",
        "  print(f\"Target: {target}, Pred: {pred}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0, Pred: 1.0, Prob: 0.9101957678794861\n",
            "Text:\n",
            "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8769819736480713\n",
            "Text:\n",
            "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8523000478744507\n",
            "Text:\n",
            "@noah_anyname That's where the concentration camps and mass murder come in. \n",
            " \n",
            "EVERY. FUCKING. TIME.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8354544043540955\n",
            "Text:\n",
            "Ashes 2015: AustraliaÛªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8272132873535156\n",
            "Text:\n",
            "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8148158192634583\n",
            "Text:\n",
            "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8108395338058472\n",
            "Text:\n",
            "[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.80312180519104\n",
            "Text:\n",
            "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.7669008374214172\n",
            "Text:\n",
            "@freefromwolves GodsLove &amp; #thankU brother Danny for RT of NEW VIDEO http://t.co/cybKsXHF7d The Coming Apocalyptic US Earthquake &amp; Tsunami\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.7666250467300415\n",
            "Text:\n",
            "Air Group is here to the rescue! We have 24/7 Emergency Service! Learn more about it here - http://t.co/9lyx7zMtHE http://t.co/5PbC96rTMJ\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNyFzpbYe9OM",
        "outputId": "5eb379e5-1c30-4b68-af6a-311c87e41046"
      },
      "source": [
        "# Check the false negatves (model predicted 0 when should've been 1)\n",
        "for row in most_wrong[-10:].itertuples():\n",
        "  _, text, target, pred, pred_prob = row\n",
        "  print(f\"Target: {target}, Pred: {pred}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 1, Pred: 0.0, Prob: 0.06730346381664276\n",
            "Text:\n",
            "@DavidVonderhaar At least you were sincere ??\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.05507579818367958\n",
            "Text:\n",
            "@willienelson We need help! Horses will die!Please RT &amp; sign petition!Take a stand &amp; be a voice for them! #gilbert23 https://t.co/e8dl1lNCVu\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.05460337549448013\n",
            "Text:\n",
            "Lucas Duda is Ghost Rider. Not the Nic Cage version but an actual 'engulfed in flames' badass. #Mets\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.054596975445747375\n",
            "Text:\n",
            "going to redo my nails and watch behind the scenes of desolation of smaug ayyy\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.04963727295398712\n",
            "Text:\n",
            "You can never escape me. Bullets don't harm me. Nothing harms me. But I know pain. I know pain. Sometimes I share it. With someone like you.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.043918490409851074\n",
            "Text:\n",
            "@SoonerMagic_ I mean I'm a fan but I don't need a girl sounding off like a damn siren\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.04208683222532272\n",
            "Text:\n",
            "I get to smoke my shit in peace\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.03899792954325676\n",
            "Text:\n",
            "Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.03894946351647377\n",
            "Text:\n",
            "Reddit Will Now QuarantineÛ_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.03718579187989235\n",
            "Text:\n",
            "Ron &amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZWUtZWDflPI"
      },
      "source": [
        "## Making predictions on the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyQmJO9qghzH",
        "outputId": "4c0b9260-5737-47b8-9fe9-0e6717a3ea77"
      },
      "source": [
        "# Making predictions on the test dataset and visualizing them\n",
        "test_sentences = test_df[\"text\"].to_list()\n",
        "test_samples = random.sample(test_sentences, 10)\n",
        "for test_sample in test_samples:\n",
        "  pred_prob = tf.squeeze(model_6_pretrained.predict([test_sample])) # our model except single sentence\n",
        "  pred = tf.round(pred_prob)\n",
        "  print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{test_sample}\\n\")\n",
        "  print(\"-----\\n\")"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 0, Prob: 0.4940234422683716\n",
            "Text:\n",
            "@Statoilasa &amp; @TOTAL make significant discovery in the North Sea: Visualise the full potential on our seismic     #g http://t.co/ve2eBqm21B\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 0, Prob: 0.029834754765033722\n",
            "Text:\n",
            "@OrianaArzola does he not have any manners or something? Jfc. You have all the rights to be mad! But hey try not to let this ruin your day\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 0, Prob: 0.03458905220031738\n",
            "Text:\n",
            "@_Souuul * gains super powers im now lava girl throws you ina chest wrapped in chains &amp; sinks you down the the bottom of the ocean*\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 0, Prob: 0.1994980275630951\n",
            "Text:\n",
            "@spikepoint @skie It's about context too. If his dick slipped out during the super bowl people would be throwing hellfire here.\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 0, Prob: 0.09474166482686996\n",
            "Text:\n",
            "Warcraft 3-Inspired Mode Likely Hitting Heroes of the Storm http://t.co/848CVWWdOt\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 1, Prob: 0.9639574289321899\n",
            "Text:\n",
            "Families to sue over Legionnaires: More than 40 families affected by the fatal outbreak of Legionnaires' disea... http://t.co/boZfh1M3wb\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 0, Prob: 0.0994633361697197\n",
            "Text:\n",
            "#tornado #singapore Mac and #cheese #around the world - mac cheese cookbook: http://t.co/rgAm3eQOwn Mac and Ch http://t.co/X6ZJpzB8UP\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 0, Prob: 0.07598628848791122\n",
            "Text:\n",
            "You're getting drowned out yet I still search for you.\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 0, Prob: 0.411969393491745\n",
            "Text:\n",
            "@mickbland27 It is disturbing! Emergency services &amp; first responders should work together not slander try &amp; get each other killed.\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 0, Prob: 0.04778318852186203\n",
            "Text:\n",
            "Businesses are deluged with invoicew. Make yours stand out with colouj or shape and it's likely to rise to the top of the pay' pile.\n",
            "\n",
            "-----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSH5vqN0hW1R"
      },
      "source": [
        "## The speed/score tradeoff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4piqm7xwimL8"
      },
      "source": [
        "# Let's make a function to measuere the time of prediction\n",
        "import time\n",
        "def pred_timer(model, samples):\n",
        "  \"\"\"\n",
        "  Times how long a model takes to make predictions on samples\n",
        "  \"\"\"\n",
        "  start_time = time.perf_counter()  # get start time\n",
        "  model.predict(samples)  # make predictions\n",
        "  end_time = time.perf_counter()  # get finish time\n",
        "  total_time = end_time-start_time  # calculate how long predictions took to make prediction\n",
        "  time_per_pred = total_time/len(samples)\n",
        "  return total_time, time_per_pred"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCF_Ha0dtfME",
        "outputId": "d938b631-6101-45df-a919-dcd1c541be4e"
      },
      "source": [
        "# Calculate TF Hub Sentence Encoder time per pred\n",
        "model_6_total_pred_time, model_6_time_per_pred = pred_timer(model=model_6_pretrained,\n",
        "                                                            samples=val_sentences)\n",
        "model_6_total_pred_time, model_6_time_per_pred"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3998279970001022, 0.000524708657480449)"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDUswiYRt3Xn"
      },
      "source": [
        "# Calculate our baseline model times per pred\n",
        "baseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0, val_sentences)"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tivFuwEavpqb"
      },
      "source": [
        "model_6_pretrained_results = calculate_results(y_true=val_labels,\n",
        "                                               y_pred=model_6_pretrained_preds)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "wdWPGpnbvc8t",
        "outputId": "96077d19-ba66-4f41-d3a6-2d0184e2e3f1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.scatter(baseline_time_per_pred, baseline_results[\"f1\"], label=\"baseline\")\n",
        "plt.scatter(model_6_time_per_pred, model_6_pretrained_results[\"f1\"], label=\"tf_hub_sentences_encoder\")\n",
        "plt.legend()\n",
        "plt.title(\"F1-score versus time per prediction\")\n",
        "plt.xlabel(\"Time per prediction\")\n",
        "plt.ylabel(\"F1-score\");"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}