{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_Neural_Network_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1kCpcg2ebw3_u58HteiZ0wC7ClrKc0iyc",
      "authorship_tag": "ABX9TyNnESZvrjiQKcZn3JD1kvEK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShahZebYousafzai/Deep-Learning-Basics/blob/main/2_Neural_Network_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W1TcZAeLAB_"
      },
      "source": [
        "# Introduction to Regression with Neural Network\n",
        "\n",
        "There are many definitions for a regression problem but in our case, we are going to simplify it: predicting a neumerical based on some other combination of variables, even shorter ... predicting a number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HELDg2usGRdC",
        "outputId": "31615538-fa64-414e-a29a-b1b317c3d27f"
      },
      "source": [
        "# Import TensorFlow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuiOcqGrLpPe"
      },
      "source": [
        "## Creating a data to view and fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "1gicmcnULiuZ",
        "outputId": "cb8feef1-f61c-4a64-ee3f-7679cdcfd8a9"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create features\n",
        "X = np.array([-7.0, -4.0, -1.0, 2.0, 6.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "# Create labels\n",
        "y = np.array([3.0, 6.0, 9.0, 12.0, 16.0, 18.0, 21.0, 24.0])\n",
        "\n",
        "# Visualize it\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.scatter(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f58875f3a90>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efbU2gpeMQw_",
        "outputId": "4c348683-0794-4916-b2ca-e7962377eb52"
      },
      "source": [
        "y == X + 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osWNkWizMtOB"
      },
      "source": [
        "## Input and Output shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXNX-0GOMdNT",
        "outputId": "6a3a4b78-5f20-466b-f49c-3620525a4ccf"
      },
      "source": [
        "# Create a demo tensor for our housing price prediction\n",
        "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
        "house_price = tf.constant([939700])\n",
        "house_info, house_price"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTMqwj2ENggC",
        "outputId": "2b489753-1e36-4f42-f2b3-93695ed7593f"
      },
      "source": [
        "X[0], y[0] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-7.0, 3.0)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvKIYGaQNnnu",
        "outputId": "c737c719-72cf-4761-eff8-1ed17b823775"
      },
      "source": [
        "X[1], y[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-4.0, 6.0)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjDF5iXqM3n8",
        "outputId": "13962393-c29b-4d57-ca04-2fc95d6d631b"
      },
      "source": [
        "input_shape = X.shape\n",
        "output_shape = y.shape\n",
        "input_shape, output_shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8,), (8,))"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAw5vxktNaVX",
        "outputId": "3923d578-488d-4d0e-d8da-f8e1f8525854"
      },
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((), ())"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaT3SKI9N2_0",
        "outputId": "d0eb9e8e-d90d-408d-c954-d53e4554958d"
      },
      "source": [
        "X[0].ndim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMPwWWY7N7pV",
        "outputId": "f61c1804-ca3d-42ea-d14c-5d561051faee"
      },
      "source": [
        "X[0], y[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-7.0, 3.0)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YE1O92FNODsc",
        "outputId": "48127025-bc81-4266-c78e-7c770adab718"
      },
      "source": [
        "# Turn our numpy arrays into tensors\n",
        "X = tf.cast(tf.constant(X), dtype=tf.float32)\n",
        "y = tf.cast(tf.constant(y), dtype=tf.float32)\n",
        "X, y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  6.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 16., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHRtMdGhOQhs",
        "outputId": "8bc1e47d-d948-425b-a947-7b1c22fd770d"
      },
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "8vwCu0GyOTq0",
        "outputId": "38fbb6bc-7c3b-43bf-ada5-e67fd249558e"
      },
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "plt.scatter(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f58874da510>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ1H5YYzOeSA"
      },
      "source": [
        "## Steps in modelling with Tensorflow\n",
        "\n",
        "1. **Creating a model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
        "2. **Compiling a model**- define the loss function (in others words, the function which tells our model how wrong it is) and the optimizer (tells our model how to improve the patterns its learning) and evaluation metrices (what we can use to interpret the performance of our model).\n",
        "3. **Fitting a model** - letting the try to find patterns between X & y (features and labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7xDRfOGOcdk",
        "outputId": "5a47a194-0d26-4207-931b-6e1649907c71"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(1)                              \n",
        "                            ])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae, # Mean Absolute Error for mae\n",
        "              optimizer=tf.keras.optimizers.SGD(),  # Stochastic Gradient Descent for sgd\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(X, y, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 254ms/step - loss: 11.5585 - mae: 11.5585\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.4171 - mae: 11.4171\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.2757 - mae: 11.2757\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.1343 - mae: 11.1343\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.9929 - mae: 10.9929\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f588749df50>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcswUWsNSJ81",
        "outputId": "1da07513-0ddb-4f7e-9fe6-5c5fea5b1d88"
      },
      "source": [
        "# Check out X and y\n",
        "X, y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  6.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 16., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPhWKNJ8aC6w",
        "outputId": "c149be12-2685-4fde-8122-93568062329c"
      },
      "source": [
        "# Try and make a prediction using our model\n",
        "y_pred = model.predict([17.0])\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f588744cc20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.8222685]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m-l9j4QaOFI",
        "outputId": "db9e71a8-f8ec-4fc5-b447-1dbe46456fb9"
      },
      "source": [
        "y_pred + 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[22.82227]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWi4yMDNahI3"
      },
      "source": [
        "## Improving our model\n",
        "\n",
        "We can improve our model, by altering the steps we took to create a model.\n",
        "\n",
        "1. **Creating a model** - here we might add more layers, increase the number of layers, increase the number of hidden units (all called neurons) withing each of the hidden layers, change the activation function of each layer.\n",
        "2. **Compiling a model** - here we might change the optimization function or perhaps the **learning rate** of the optimization function.\n",
        "3. **Fitting the model** - here we might fit our model for more **epochs** (leaving it for training a little longer) or on more data (give model more examples to learn from)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHHO_Vhlhc8b"
      },
      "source": [
        "### Let's rebuild our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpMekpMdiAEb"
      },
      "source": [
        "#### Increasing the epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMlhfIsNad5y",
        "outputId": "4e390b02-3c50-4c57-a061-1fa3ff486396"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(1)                              \n",
        "                            ])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae, # Mean Absolute Error for mae\n",
        "              optimizer=tf.keras.optimizers.SGD(),  # Stochastic Gradient Descent for sgd\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model (this time increase the epochs)\n",
        "model.fit(X, y, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 11.5585 - mae: 11.5585\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.4171 - mae: 11.4171\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.2757 - mae: 11.2757\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.1343 - mae: 11.1343\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.9929 - mae: 10.9929\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.8515 - mae: 10.8515\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.7101 - mae: 10.7101\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.5687 - mae: 10.5687\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.4273 - mae: 10.4273\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.2859 - mae: 10.2859\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.1445 - mae: 10.1445\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.0031 - mae: 10.0031\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.8617 - mae: 9.8617\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.7203 - mae: 9.7203\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.5788 - mae: 9.5788\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.4374 - mae: 9.4374\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.2960 - mae: 9.2960\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.1546 - mae: 9.1546\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.0132 - mae: 9.0132\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.8718 - mae: 8.8718\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.7304 - mae: 8.7304\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.5890 - mae: 8.5890\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.4476 - mae: 8.4476\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3062 - mae: 8.3062\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.1648 - mae: 8.1648\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.0234 - mae: 8.0234\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.8820 - mae: 7.8820\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.7406 - mae: 7.7406\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.5992 - mae: 7.5992\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.4578 - mae: 7.4578\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.3163 - mae: 7.3163\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1808 - mae: 7.1808\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1750 - mae: 7.1750\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1692 - mae: 7.1692\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1634 - mae: 7.1634\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1576 - mae: 7.1576\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1519 - mae: 7.1519\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1461 - mae: 7.1461\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1403 - mae: 7.1403\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1345 - mae: 7.1345\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1287 - mae: 7.1287\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1230 - mae: 7.1230\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1172 - mae: 7.1172\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1114 - mae: 7.1114\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1056 - mae: 7.1056\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0998 - mae: 7.0998\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0941 - mae: 7.0941\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0883 - mae: 7.0883\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0825 - mae: 7.0825\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0767 - mae: 7.0767\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0709 - mae: 7.0709\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0651 - mae: 7.0651\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0594 - mae: 7.0594\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0536 - mae: 7.0536\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0478 - mae: 7.0478\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.0420 - mae: 7.0420\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.0362 - mae: 7.0362\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0305 - mae: 7.0305\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0247 - mae: 7.0247\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0189 - mae: 7.0189\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0131 - mae: 7.0131\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0073 - mae: 7.0073\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0016 - mae: 7.0016\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9958 - mae: 6.9958\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9900 - mae: 6.9900\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9842 - mae: 6.9842\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9784 - mae: 6.9784\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9726 - mae: 6.9726\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9669 - mae: 6.9669\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9611 - mae: 6.9611\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.9553 - mae: 6.9553\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.9495 - mae: 6.9495\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9437 - mae: 6.9437\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9380 - mae: 6.9380\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9322 - mae: 6.9322\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9264 - mae: 6.9264\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9206 - mae: 6.9206\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9148 - mae: 6.9148\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9091 - mae: 6.9091\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9033 - mae: 6.9033\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.8975 - mae: 6.8975\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8917 - mae: 6.8917\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8859 - mae: 6.8859\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8801 - mae: 6.8801\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8744 - mae: 6.8744\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8686 - mae: 6.8686\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.8628 - mae: 6.8628\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8570 - mae: 6.8570\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.8512 - mae: 6.8512\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8455 - mae: 6.8455\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.8397 - mae: 6.8397\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.8339 - mae: 6.8339\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.8281 - mae: 6.8281\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8223 - mae: 6.8223\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.8166 - mae: 6.8166\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.8108 - mae: 6.8108\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.8050 - mae: 6.8050\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.7992 - mae: 6.7992\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.7934 - mae: 6.7934\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.7876 - mae: 6.7876\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f58873ea0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXBBHYUfhqjq",
        "outputId": "75649c54-bd3f-47dd-f40a-1444ae287de4"
      },
      "source": [
        "# Check out X and y\n",
        "X, y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  6.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 16., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd4uIUK8hxZ_",
        "outputId": "56d54cc1-6341-47bc-bd2b-059a0d544a1b"
      },
      "source": [
        "# Check if our model imroved\n",
        "y_pred = model.predict([17.0])\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f58dead95f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[31.088549]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKJpHm2biG6s"
      },
      "source": [
        "#### Add 2 more hidden layers with 100 hidden units"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjIwF418h044",
        "outputId": "cd9ea678-d0da-418d-b048-e729355e0ecb"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(1),\n",
        "                             tf.keras.layers.Dense(1),\n",
        "                             tf.keras.layers.Dense(1)                              \n",
        "                            ])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae, # Mean Absolute Error for mae\n",
        "              optimizer=tf.keras.optimizers.SGD(),  # Stochastic Gradient Descent for sgd\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model (this time increase the epochs)\n",
        "model.fit(X, y, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 12.5004 - mae: 12.5004\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12.3912 - mae: 12.3912\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 12.2718 - mae: 12.2718\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 12.1408 - mae: 12.1408\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.9965 - mae: 11.9965\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.8372 - mae: 11.8372\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.6604 - mae: 11.6604\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.4636 - mae: 11.4636\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.2436 - mae: 11.2436\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.9966 - mae: 10.9966\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.7181 - mae: 10.7181\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.4027 - mae: 10.4027\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.0438 - mae: 10.0438\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.6331 - mae: 9.6331\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.1610 - mae: 9.1610\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.6148 - mae: 8.6148\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.9795 - mae: 7.9795\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2355 - mae: 7.2355\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8929 - mae: 6.8929\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.8596 - mae: 6.8596\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8496 - mae: 6.8496\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.8455 - mae: 6.8455\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.8134 - mae: 6.8134\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.7808 - mae: 6.7808\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.7475 - mae: 6.7475\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.7137 - mae: 6.7137\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.6793 - mae: 6.6793\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.6442 - mae: 6.6442\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.6085 - mae: 6.6085\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.5763 - mae: 6.5763\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.5987 - mae: 6.5987\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.5638 - mae: 6.5638\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.5281 - mae: 6.5281\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.4917 - mae: 6.4917\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.4546 - mae: 6.4546\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.4166 - mae: 6.4166\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.3777 - mae: 6.3777\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.3446 - mae: 6.3446\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.3702 - mae: 6.3702\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.3318 - mae: 6.3318\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.2926 - mae: 6.2926\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.2524 - mae: 6.2524\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.2112 - mae: 6.2112\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.1690 - mae: 6.1690\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.1283 - mae: 6.1283\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.1620 - mae: 6.1620\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.1199 - mae: 6.1199\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.0768 - mae: 6.0768\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.0326 - mae: 6.0326\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.9872 - mae: 5.9872\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.9406 - mae: 5.9406\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.9480 - mae: 5.9480\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.9328 - mae: 5.9328\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.8860 - mae: 5.8860\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.8379 - mae: 5.8379\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.7884 - mae: 5.7884\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.7375 - mae: 5.7375\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.7529 - mae: 5.7529\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.7277 - mae: 5.7277\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.6762 - mae: 5.6762\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.6232 - mae: 5.6232\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.5686 - mae: 5.5686\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.5323 - mae: 5.5323\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.5558 - mae: 5.5558\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.5002 - mae: 5.5002\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.4429 - mae: 5.4429\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3838 - mae: 5.3838\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3246 - mae: 5.3246\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.3931 - mae: 5.3931\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.5017 - mae: 5.5017\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.2292 - mae: 5.2292\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.1641 - mae: 5.1641\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.1945 - mae: 5.1945\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.1427 - mae: 5.1427\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.0757 - mae: 5.0757\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.0065 - mae: 5.0065\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.9477 - mae: 4.9477\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.0265 - mae: 5.0265\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.1274 - mae: 5.1274\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.8180 - mae: 4.8180\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.7730 - mae: 4.7730\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.8294 - mae: 4.8294\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.9539 - mae: 4.9539\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.6108 - mae: 4.6108\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.5932 - mae: 4.5932\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.5999 - mae: 4.5999\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.7757 - mae: 4.7757\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.3816 - mae: 4.3816\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.4040 - mae: 4.4040\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.3366 - mae: 4.3366\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.5883 - mae: 4.5883\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.1608 - mae: 4.1608\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.2860 - mae: 4.2860\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.3401 - mae: 4.3401\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9495 - mae: 3.9495\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9459 - mae: 3.9459\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9610 - mae: 3.9610\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.1778 - mae: 4.1778\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9734 - mae: 3.9734\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.9213 - mae: 3.9213\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f58dea36ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGNh_KJCilXC",
        "outputId": "f2453821-b98c-470d-fc21-fc5ecb198d5a"
      },
      "source": [
        "# Check if our model imroved\n",
        "y_pred = model.predict([17.0])\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.246553]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI8q_29hiuRe"
      },
      "source": [
        "#### Changing the optimizer SGD to Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfcQ1N7ziqNY",
        "outputId": "769dd919-5c71-48e4-ef3b-5289d1b572e0"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(50),\n",
        "                             tf.keras.layers.Dense(1)                            \n",
        "                            ])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae, # Mean Absolute Error for mae\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=0.1),  # Stochastic Gradient Descent for sgd\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model (this time increase the epochs)\n",
        "model.fit(X, y, epochs=200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 13.2957 - mae: 13.2957\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.6569 - mae: 6.6569\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 13.4015 - mae: 13.4015\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.7621 - mae: 7.7621\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1542 - mae: 7.1542\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.4987 - mae: 8.4987\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.0912 - mae: 8.0912\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.5421 - mae: 6.5421\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.0528 - mae: 4.0528\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9951 - mae: 2.9951\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.3004 - mae: 3.3004\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.1985 - mae: 1.1985\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.9975 - mae: 2.9975\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.3198 - mae: 4.3198\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.5724 - mae: 3.5724\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6490 - mae: 1.6490\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6210 - mae: 2.6210\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9139 - mae: 2.9139\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9285 - mae: 1.9285\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0840 - mae: 2.0840\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0706 - mae: 3.0706\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6696 - mae: 2.6696\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0805 - mae: 1.0805\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3190 - mae: 2.3190\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0872 - mae: 3.0872\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5801 - mae: 2.5801\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1593 - mae: 1.1593\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9658 - mae: 1.9658\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0468 - mae: 3.0468\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.1426 - mae: 3.1426\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4163 - mae: 2.4163\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9936 - mae: 0.9936\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2878 - mae: 1.2878\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3059 - mae: 2.3059\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1093 - mae: 2.1093\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9188 - mae: 0.9188\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0906 - mae: 1.0906\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9547 - mae: 1.9547\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9349 - mae: 1.9349\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1968 - mae: 1.1968\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4647 - mae: 0.4647\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9927 - mae: 0.9927\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6003 - mae: 0.6003\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6144 - mae: 0.6144\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8681 - mae: 0.8681\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3261 - mae: 0.3261\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0174 - mae: 1.0174\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3229 - mae: 1.3229\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7100 - mae: 0.7100\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6757 - mae: 0.6757\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0834 - mae: 1.0834\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7620 - mae: 0.7620\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3936 - mae: 0.3936\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5448 - mae: 0.5448\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1032 - mae: 0.1032\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1518 - mae: 0.1518\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4599 - mae: 0.4599\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2660 - mae: 0.2660\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6612 - mae: 0.6612\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7146 - mae: 0.7146\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0182\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1398 - mae: 0.1398\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5211 - mae: 0.5211\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3636 - mae: 0.3636\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5177 - mae: 0.5177\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5588 - mae: 0.5588\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2030 - mae: 0.2030\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1126 - mae: 0.1126\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6543 - mae: 0.6543\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5759 - mae: 0.5759\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2341 - mae: 0.2341\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2453 - mae: 0.2453\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4621 - mae: 0.4621\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3778 - mae: 0.3778\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4022 - mae: 0.4022\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4283 - mae: 0.4283\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2889 - mae: 0.2889\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1982 - mae: 0.1982\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5990 - mae: 0.5990\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6275 - mae: 0.6275\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0391 - mae: 0.0391\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2770 - mae: 0.2770\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3340 - mae: 0.3340\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2662 - mae: 0.2662\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2373 - mae: 0.2373\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2036 - mae: 0.2036\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3419 - mae: 0.3419\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2359 - mae: 0.2359\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2451 - mae: 0.2451\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4394 - mae: 0.4394\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.3713 - mae: 0.3713\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4890 - mae: 0.4890\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4514 - mae: 0.4514\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3596 - mae: 0.3596\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2987 - mae: 0.2987\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3599 - mae: 0.3599\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2020 - mae: 0.2020\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5740 - mae: 0.5740\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5900 - mae: 0.5900\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1721 - mae: 0.1721\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1936 - mae: 0.1936\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4364 - mae: 0.4364\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2278 - mae: 0.2278\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6936 - mae: 0.6936\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7730 - mae: 0.7730\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1383 - mae: 0.1383\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0465 - mae: 1.0465\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4115 - mae: 1.4115\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1102 - mae: 1.1102\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2540 - mae: 0.2540\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1476 - mae: 1.1476\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4671 - mae: 1.4671\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0674 - mae: 1.0674\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7084 - mae: 0.7084\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8983 - mae: 0.8983\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3003 - mae: 0.3003\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0368 - mae: 1.0368\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4217 - mae: 1.4217\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9300 - mae: 0.9300\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.8716 - mae: 0.8716\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1337 - mae: 1.1337\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7953 - mae: 0.7953\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2743 - mae: 0.2743\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6019 - mae: 0.6019\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3115 - mae: 0.3115\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7086 - mae: 0.7086\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7997 - mae: 0.7997\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4331 - mae: 0.4331\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0952 - mae: 1.0952\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2501 - mae: 1.2501\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6375 - mae: 0.6375\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6181 - mae: 0.6181\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0346 - mae: 1.0346\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7642 - mae: 0.7642\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2064 - mae: 0.2064\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4251 - mae: 0.4251\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3795 - mae: 0.3795\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3133 - mae: 0.3133\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3425 - mae: 0.3425\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2263 - mae: 0.2263\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6935 - mae: 0.6935\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6740 - mae: 0.6740\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0564 - mae: 0.0564\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1805 - mae: 1.1805\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5667 - mae: 1.5667\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1612 - mae: 1.1612\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1822 - mae: 0.1822\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3721 - mae: 1.3721\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0400 - mae: 2.0400\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.0778 - mae: 2.0778\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6312 - mae: 1.6312\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7116 - mae: 0.7116\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1753 - mae: 1.1753\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8552 - mae: 1.8552\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7106 - mae: 1.7106\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0278 - mae: 1.0278\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8688 - mae: 0.8688\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3897 - mae: 1.3897\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2397 - mae: 1.2397\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5088 - mae: 0.5088\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8891 - mae: 0.8891\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4156 - mae: 1.4156\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1356 - mae: 1.1356\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3292 - mae: 0.3292\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9282 - mae: 0.9282\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0703 - mae: 1.0703\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5359 - mae: 0.5359\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7795 - mae: 0.7795\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1276 - mae: 1.1276\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6281 - mae: 0.6281\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5615 - mae: 0.5615\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8857 - mae: 0.8857\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5480 - mae: 0.5480\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4836 - mae: 0.4836\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6605 - mae: 0.6605\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0940 - mae: 0.0940\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0212 - mae: 1.0212\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3655 - mae: 1.3655\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0712 - mae: 1.0712\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1860 - mae: 0.1860\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3129 - mae: 1.3129\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8902 - mae: 1.8902\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5694 - mae: 1.5694\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5391 - mae: 0.5391\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0068 - mae: 1.0068\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5378 - mae: 1.5378\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3723 - mae: 1.3723\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6202 - mae: 0.6202\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8256 - mae: 1.8256\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0566 - mae: 2.0566\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0690 - mae: 1.0690\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7399 - mae: 0.7399\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3257 - mae: 1.3257\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0297 - mae: 1.0297\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4260 - mae: 0.4260\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4666 - mae: 0.4666\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2848 - mae: 0.2848\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3732 - mae: 0.3732\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3174 - mae: 0.3174\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2461 - mae: 0.2461\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f58de934910>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrZu94Dhq2PP",
        "outputId": "2b2dbbb7-90da-4c5b-9ec3-9b39cc52065f"
      },
      "source": [
        "# Check if our model imroved\n",
        "y_pred = model.predict([17.0])\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[27.52472]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwU8ad5axqeM"
      },
      "source": [
        "## Evaluating a model\n",
        "\n",
        "In practice, a typical workflow you'll go through when building neural network is\n",
        "\n",
        "```\n",
        "Build a model -> fit it -> evaluate it -> tweak a mode - > fit it -> evaluate it -> tweak a mode -> evaluate it ...\n",
        "```\n",
        "\n",
        ">  In above model the things we tweaked are called `hyperparameter`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2Y_rtqxyWCx"
      },
      "source": [
        "When it comes to evaluation ... there are 3 words you should memorize:\n",
        "\n",
        "> \"Visualize, visualize, visualize\"\n",
        "\n",
        "It's a good idea to visualize:\n",
        "* THe data - what data are we working with? What does it look like?\n",
        "* The model itsel - what our model looks like?\n",
        "* The training of a model - how does a model perform while it learns?\n",
        "* The predictions of the model - how do the predictions of a model line up against the ground truth (the original labels)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsCMDAZZq4w1",
        "outputId": "75a82a2a-cb7f-4992-a415-fe4408cd805e"
      },
      "source": [
        "# Make a bigger dataset\n",
        "X = tf.range(-100, 100, 4)\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAOM9h6mzRUc",
        "outputId": "efceb207-ce26-4f3a-bc42-5fa1d53b4e00"
      },
      "source": [
        "# Make labels for the dateset\n",
        "y = X +10\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "daH3vSvrzZZd",
        "outputId": "f40e52a6-4616-4c68-ba23-27976e4d30b4"
      },
      "source": [
        "# Visualize the data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.scatter(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f58de853a10>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Utxn227NzsAG"
      },
      "source": [
        "### The 3 sets ...\n",
        "\n",
        "* **Training set** - the model learns from this data which is tpically 70-80% of the total data you have available.\n",
        "* **Validation set** - the model gets tuned on this data, which is typically 10-15% of the data available.\n",
        "* **Test set** - the model gets evaluated on this data to test what it has learned, this set is typically 10-15% of the total data available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eN7Q_QgKzl2c",
        "outputId": "1a408619-ed38-4ee2-f19a-8fd9e09c220f"
      },
      "source": [
        "# Check the length of how many samples we have\n",
        "len(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YGDdatl1ECz",
        "outputId": "c972e828-0374-4556-b9fb-dc70f10c4d81"
      },
      "source": [
        "# Split the data into train and test sets\n",
        "X_train = X[:40]  # first 40 are training samples (80% of the data)\n",
        "y_train = y[:40]\n",
        "\n",
        "X_test = X[40:]   # first 10 are testing samples (10% of the data)\n",
        "y_test = y[40:]\n",
        "\n",
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 10, 40, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaZzUlym14if"
      },
      "source": [
        "### Visualizing the data\n",
        "\n",
        "Now we've got out data in the training and test set ... let's visualize it again!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "YrPc0jRL13gt",
        "outputId": "d025d478-87fd-4896-9528-c64dbf7a3c97"
      },
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "\n",
        "# Plot training data in blue\n",
        "plt.scatter(X_train, y_train, c=\"b\", label=\"Training data\") # our model will learn on this\n",
        "# Plot test data in green\n",
        "plt.scatter(X_test, y_test, c=\"g\", label=\"Testing data\")    # want our model to be able to predict this (given X, what's y?)\n",
        "# Show a legend\n",
        "plt.legend();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqvc-lJU2aYx"
      },
      "source": [
        "# Let's have a look how to build a neural network for our data\n",
        "\n",
        "# 1. create a model\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "# model.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgrYhy1fYjIG"
      },
      "source": [
        "### Visualizing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "epkb8NvJYiin",
        "outputId": "3c79b128-e3a6-4412-9d26-d397d5f2acf5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   2519\u001b[0m     \"\"\"\n\u001b[1;32m   2520\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2521\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   2522\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2523\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxWujrZeZkyG"
      },
      "source": [
        " The above error is because we have not fit the model but if we define the input shape to our layer we can get the models information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoyKAPYqYnc-"
      },
      "source": [
        "# Let's create a model which builds automatically by defining the input_shape argument\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(10, input_shape=[1])\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngXpu9aBZcUR",
        "outputId": "3f061643-140d-46a5-94ea-33d5d87e1039"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 10)                20        \n",
            "=================================================================\n",
            "Total params: 20\n",
            "Trainable params: 20\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCv5w0cNZ5Rz"
      },
      "source": [
        "* Total params - total number of parameters in the model.\n",
        "* Trainable parameters - these are the parameters (patterns) the model can update as it trains.\n",
        "* Non-trainable params - these parameters aren't updated during training (this is typically when you bring in already learned patterns or parameters from other models during **transfer learning**)\n",
        "\n",
        ">  **Resource:** For a more in-depth overview of the trainable parameters within layers, check out [MIT's introduction to deep learning video](http://introtodeeplearning.com/). \n",
        "\n",
        ">  **Exercise:** Try laying around with the number of hidden units in the dense layer, see how that effects the number of parameters (total and trainable) by calling `model.summary()`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZoAu8uDZeHm",
        "outputId": "7e49ca48-14c3-4a4e-e410-8d5d584e1f89"
      },
      "source": [
        "# Let's fit our model to training data\n",
        "model.fit(X_train, y_train, epochs=100, verbose=0) # with verbose we can see how our model trains"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6b2b6cfad0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9pRtChrcXdA",
        "outputId": "50255492-2f70-48c9-8439-b15c4316aef7"
      },
      "source": [
        "# Get a summary of our model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 10)                20        \n",
            "=================================================================\n",
            "Total params: 20\n",
            "Trainable params: 20\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "UIe0gLKHcvMe",
        "outputId": "a7c08ea2-3257-4c23-c758-7afe9b7e8b53"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model=model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jk5NUm25dZfu"
      },
      "source": [
        "# Let's create a model which builds automatically by defining the input_shape argument\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(1, input_shape=[1]),\n",
        "                             tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVbsVJtMnTF8",
        "outputId": "932cc486-000f-4f10-d30d-cb6fcdde4c2f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_11 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 4\n",
            "Trainable params: 4\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "tZKJKHnfnXbM",
        "outputId": "a30a9366-b66e-426e-91d8-394a17477d53"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model=model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLwrnqfQnyjE"
      },
      "source": [
        "### Visualizing our model's prediction\n",
        "\n",
        "To visualize predictions, it's a good idea to plot them against the ground truth labels.\n",
        "\n",
        "Ofeten we'll see this in the form of `y_test` or `y_true` versus `y_pred` (ground truth versus your model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmIc5Z_onZ5c",
        "outputId": "4e5dd0e8-d90d-4d37-c982-fe1580f70ba0"
      },
      "source": [
        "# Make some predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6b2c2459e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[22.26224 ],\n",
              "       [23.746387],\n",
              "       [25.230537],\n",
              "       [26.714685],\n",
              "       [28.198835],\n",
              "       [29.682983],\n",
              "       [31.167135],\n",
              "       [32.651283],\n",
              "       [34.135433],\n",
              "       [35.619583]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqTlFHhcosJb",
        "outputId": "18893b76-bf3a-444a-a66d-0f7aa9e56180"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riV2fvJPq8oG"
      },
      "source": [
        ">  **Note:** If you feel like you're going to reuse some kind of functionality in the future, it's a good idea to turn it into a function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNKsNSkPpObU"
      },
      "source": [
        "# Let's create a plotting function\n",
        "def plot_predictions(train_data=X_train,\n",
        "                     train_labels=y_train,\n",
        "                     test_data=X_test,\n",
        "                     test_labels=y_test,\n",
        "                     predictions=y_pred):\n",
        "  \"\"\"\n",
        "  Plot training data, test data and compare predictions to ground truth labels\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10,7))\n",
        "  # Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n",
        "  # Plot the testing data in green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", label=\"Testing data\")\n",
        "  # Plot model's predictions in red\n",
        "  plt.scatter(test_data, predictions, c=\"r\", label=\"Predictions\")\n",
        "  # Show the legend\n",
        "  plt.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "CYkQ_4EBrZeG",
        "outputId": "4c067c44-4eaa-49be-95ad-1630ab6b0a93"
      },
      "source": [
        "plot_predictions()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGp-l1cFugTi"
      },
      "source": [
        "### Evaluating our mode's predictions with regression evaluation metrices\n",
        "\n",
        "Depending on the problem you're working on, there will be different evaluation metrics to evaluate your model's performance.\n",
        "\n",
        "Since we're working on a regression, two of the main metrics:\n",
        "* MAE - mean absolute error \"on avarage, how wrong is each of my model's predictions\".\n",
        "* MSE - mean square error, \"square the average errors\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4KR530vsO0k",
        "outputId": "01fac8ed-5c86-43ce-de8f-6128f348c208"
      },
      "source": [
        "# Evaluate the model on the test \n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 198ms/step - loss: 59.0591 - mae: 59.0591\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[59.05908966064453, 59.05908966064453]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bynXMKpxzYD",
        "outputId": "e9efd40c-bef9-4049-91a4-0dd3b3f2c168"
      },
      "source": [
        "# calculate the mean absolute error\n",
        "mae = tf.metrics.mean_absolute_error(y_true=y_test,\n",
        "                                     y_pred=tf.constant(y_pred))\n",
        "mae"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([65.73776 , 64.25362 , 62.769463, 61.285316, 59.80116 , 58.317017,\n",
              "       56.832863, 55.348717, 53.864563, 52.38042 ], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5sAM_ffxcfe",
        "outputId": "5ff4b09b-6fbc-48dc-b76b-5f2c58c9a519"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[22.26224 ],\n",
              "       [23.746387],\n",
              "       [25.230537],\n",
              "       [26.714685],\n",
              "       [28.198835],\n",
              "       [29.682983],\n",
              "       [31.167135],\n",
              "       [32.651283],\n",
              "       [34.135433],\n",
              "       [35.619583]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJBMfqT1xwkb",
        "outputId": "7d3833c6-9279-462f-e06e-fd3630c740ed"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o8srCd717VD",
        "outputId": "fc805430-b923-48a6-8e9e-bcbc00ed8ed5"
      },
      "source": [
        "y_pred.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10, 1), TensorShape([10]))"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWe5nY662Auu"
      },
      "source": [
        "**Note:** If you're comparing two tensors, it's important to make sure they're the right shape(s) (you won't always have to manipulate the shapes, but always be on the look out, many errors are the result of mismatched tensors, especially mismatched input and output shapes)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m74070lMxxYj",
        "outputId": "a916219b-0822-42cf-88dc-f497553b5c3b"
      },
      "source": [
        "tf.squeeze(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([22.26224 , 23.746387, 25.230537, 26.714685, 28.198835, 29.682983,\n",
              "       31.167135, 32.651283, 34.135433, 35.619583], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnIwyBB4y6aC",
        "outputId": "e1443305-3612-47ef-ec06-594876d2b2a6"
      },
      "source": [
        "# calculate the mean absolute error\n",
        "mae = tf.metrics.mean_absolute_error(y_true=y_test,\n",
        "                                     y_pred=tf.squeeze(y_pred))\n",
        "mae"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=59.05909>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2fvxOg6y-5z",
        "outputId": "a84a7fc4-33f0-404e-9062-81c23fef7319"
      },
      "source": [
        "mse = tf.keras.metrics.mean_squared_error(y_true=y_test,\n",
        "                                          y_pred=tf.squeeze(y_pred))\n",
        "mse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=3540.1946>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7HIoqSvzpHc"
      },
      "source": [
        "# Make some functions to reuse MAE and MSE\n",
        "def mae(y_test, y_pred):\n",
        "  return tf.metrics.mean_absolute_error(y_true=y_test,\n",
        "                                     y_pred=tf.squeeze(y_pred))\n",
        "  \n",
        "def mse(y_test, y_pred):\n",
        "  return tf.metrics.mean_squared_error(y_true=y_test,\n",
        "                                     y_pred=tf.squeeze(y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m73sH2MQ0QsK",
        "outputId": "68ab6208-027e-4006-bc3e-1c5cb6cfa777"
      },
      "source": [
        "mae(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=59.05909>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4CYY2cv0iOy",
        "outputId": "50e5d7e6-7350-459f-b03a-c1c2959046a8"
      },
      "source": [
        "mse(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=3540.1946>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GCeli311J_w"
      },
      "source": [
        "### Running experiments to improve a model\n",
        "\n",
        "After seeing the evaluation metrics and the predictions your model makes, it's likely you'll want to improve it.\n",
        "\n",
        "Again, there are many different ways you can do this, but 3 of the main ones are:\n",
        "1. **Get more data** - get more examples for your model to train on (more opportunities to learn patterns).\n",
        "2. **Make your model larger (use a more complex model)** - this might come in the form of more layers or more hidden units in each layer.\n",
        "3. **Train for longer**- give your model more of a chance to find the patterns in the data.\n",
        "\n",
        "Since we created our dataset, we could easily make more data but this isn't always the case when you're working with real-world datasets.\n",
        "\n",
        "So let's take a look at how we can improve our model using 2 and 3.\n",
        "\n",
        "To do so, we'll build 3 models and compare their results:\n",
        "\n",
        "1. `model_1` - same as original model, 1 layer, trained for 100 epochs.\n",
        "2. `model_2` - 2 layers, trained for 100 epochs.\n",
        "3. `model_3` - 2 layers, trained for 500 epochs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFThMDVA3XkD"
      },
      "source": [
        "#### **Build `model_1`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0BwxG8Y0rNu",
        "outputId": "e4ef267c-dc81-4dcc-aac1-ae55a3f9c67b"
      },
      "source": [
        "# Let's create a model which builds automatically by defining the input_shape argument\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_1 = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model\n",
        "model_1.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.9024 - mae: 15.9024\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.2837 - mae: 11.2837\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.1074 - mae: 11.1074\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2991 - mae: 9.2991\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.1677 - mae: 10.1677\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.4303 - mae: 9.4303\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.5704 - mae: 8.5704\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.0442 - mae: 9.0442\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 18.7517 - mae: 18.7517\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.1142 - mae: 10.1142\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.3980 - mae: 8.3980\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.6639 - mae: 10.6639\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.7977 - mae: 9.7977\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.0103 - mae: 16.0103\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.4068 - mae: 11.4068\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.5393 - mae: 8.5393\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 13.6348 - mae: 13.6348\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.4629 - mae: 11.4629\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.9148 - mae: 17.9148\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.0494 - mae: 15.0494\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.0216 - mae: 11.0216\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.1558 - mae: 8.1558\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.5138 - mae: 9.5138\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.6617 - mae: 7.6617\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.1859 - mae: 13.1859\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.4211 - mae: 16.4211\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.1660 - mae: 13.1660\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.2559 - mae: 14.2559\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.0670 - mae: 10.0670\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 16.3409 - mae: 16.3409\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.6444 - mae: 23.6444\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.6215 - mae: 7.6215\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.3221 - mae: 9.3221\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.7313 - mae: 13.7313\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.1276 - mae: 11.1276\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.3222 - mae: 13.3222\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.4763 - mae: 9.4763\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.1381 - mae: 10.1381\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.1793 - mae: 10.1793\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.9137 - mae: 10.9137\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.9063 - mae: 7.9063\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.0914 - mae: 10.0914\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.7006 - mae: 8.7006\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.2047 - mae: 12.2047\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.7970 - mae: 13.7970\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.4687 - mae: 8.4687\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.1330 - mae: 9.1330\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.6190 - mae: 10.6190\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.7503 - mae: 7.7503\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.5407 - mae: 9.5407\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.1584 - mae: 9.1584\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.3630 - mae: 16.3630\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.1299 - mae: 14.1299\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 21.1247 - mae: 21.1247\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.3961 - mae: 16.3961\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.9806 - mae: 9.9806\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.9606 - mae: 9.9606\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2209 - mae: 9.2209\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.4239 - mae: 8.4239\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.4869 - mae: 9.4869\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.4355 - mae: 11.4355\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.6887 - mae: 11.6887\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.9675 - mae: 16.9675\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.4599 - mae: 12.4599\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.0184 - mae: 13.0184\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.0600 - mae: 8.0600\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.1888 - mae: 10.1888\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.3633 - mae: 12.3633\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.0516 - mae: 9.0516\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.0378 - mae: 10.0378\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.0516 - mae: 10.0516\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.6151 - mae: 12.6151\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.3819 - mae: 10.3819\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.7229 - mae: 9.7229\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.2252 - mae: 11.2252\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.3642 - mae: 8.3642\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.1274 - mae: 9.1274\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.5039 - mae: 19.5039\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.8945 - mae: 14.8945\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.0034 - mae: 9.0034\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.0206 - mae: 13.0206\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.9299 - mae: 7.9299\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.6872 - mae: 7.6872\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.0328 - mae: 10.0328\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2433 - mae: 9.2433\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.0209 - mae: 12.0209\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.6389 - mae: 10.6389\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.2667 - mae: 7.2667\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.7786 - mae: 12.7786\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.3481 - mae: 7.3481\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.7175 - mae: 7.7175\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.1263 - mae: 7.1263\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.6190 - mae: 12.6190\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.0912 - mae: 10.0912\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.3558 - mae: 9.3558\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.6834 - mae: 12.6834\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 8.6762 - mae: 8.6762\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.4693 - mae: 9.4693\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.7067 - mae: 8.7067\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6b2bd643d0>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "sZboGe8I2WO1",
        "outputId": "966f5fdf-cf9b-4558-d227-452aea0512e5"
      },
      "source": [
        "# Make and plot predictions for model_1\n",
        "y_preds_1 = model_1.predict(X_test)\n",
        "plot_predictions(predictions=y_preds_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbN_WuYc25Gb",
        "outputId": "efde432a-1730-4866-afe0-3f4bb443affc"
      },
      "source": [
        "# Calculate model_1 metrics\n",
        "mae_1 = mae(y_test, y_preds_1)\n",
        "mse_1 = mse(y_test, y_preds_1)\n",
        "mae_1, mse_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=18.745327>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=353.57336>)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFVtFoop3UT-"
      },
      "source": [
        "#### Build `model_2`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPNPNiwF2-Sx",
        "outputId": "6c1ccdab-1bce-4254-f860-853d0d63a806"
      },
      "source": [
        "# Let's create a model which builds automatically by defining the input_shape argument\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_2 = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(10),\n",
        "                             tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model\n",
        "model_2.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 27.4058 - mae: 27.4058\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 24.6339 - mae: 24.6339\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 29.8935 - mae: 29.8935\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 27.4055 - mae: 27.4055\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.9463 - mae: 14.9463\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.8819 - mae: 11.8819\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.1988 - mae: 11.1988\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.0910 - mae: 11.0910\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 40.4763 - mae: 40.4763\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 27.8688 - mae: 27.8688\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.2473 - mae: 10.2473\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 25.2803 - mae: 25.2803\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.9897 - mae: 16.9897\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25.9217 - mae: 25.9217\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.9948 - mae: 17.9948\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.3510 - mae: 7.3510\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.8636 - mae: 10.8636\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 19.5304 - mae: 19.5304\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 10.3469 - mae: 10.3469\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.6985 - mae: 17.6985\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 15.8984 - mae: 15.8984\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 14.1991 - mae: 14.1991\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.7720 - mae: 8.7720\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.0570 - mae: 11.0570\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.6838 - mae: 12.6838\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 26.1877 - mae: 26.1877\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.7432 - mae: 11.7432\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 22.8730 - mae: 22.8730\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.2459 - mae: 9.2459\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 29.2641 - mae: 29.2641\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 53.0225 - mae: 53.0225\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.9951 - mae: 11.9951\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.6357 - mae: 15.6357\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.6925 - mae: 12.6925\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.2398 - mae: 9.2398\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.6497 - mae: 16.6497\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.0382 - mae: 11.0382\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.1634 - mae: 18.1634\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.1013 - mae: 19.1013\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 20.4324 - mae: 20.4324\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.9102 - mae: 14.9102\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 12.2809 - mae: 12.2809\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.7333 - mae: 10.7333\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 23.0260 - mae: 23.0260\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.3897 - mae: 10.3897\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11.7904 - mae: 11.7904\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.6438 - mae: 9.6438\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.2335 - mae: 17.2335\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.5729 - mae: 9.5729\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.8185 - mae: 13.8185\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.5958 - mae: 11.5958\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 30.5538 - mae: 30.5538\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.3541 - mae: 14.3541\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 23.9713 - mae: 23.9713\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 23.1938 - mae: 23.1938\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 10.8837 - mae: 10.8837\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 12.7445 - mae: 12.7445\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.5995 - mae: 9.5995\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.5172 - mae: 12.5172\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 12.3200 - mae: 12.3200\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.4604 - mae: 17.4604\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.6052 - mae: 10.6052\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.4893 - mae: 10.4893\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 24.8450 - mae: 24.8450\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.6761 - mae: 10.6761\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 21.7809 - mae: 21.7809\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.7136 - mae: 10.7136\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.6397 - mae: 10.6397\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 22.6914 - mae: 22.6914\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.3316 - mae: 9.3316\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.4355 - mae: 15.4355\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.7437 - mae: 6.7437\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.6891 - mae: 11.6891\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 24.0400 - mae: 24.0400\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.5896 - mae: 9.5896\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.4371 - mae: 12.4371\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.6489 - mae: 16.6489\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.0614 - mae: 9.0614\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.9675 - mae: 23.9675\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 26.7463 - mae: 26.7463\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.6714 - mae: 11.6714\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.0228 - mae: 12.0228\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.4218 - mae: 17.4218\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.2629 - mae: 7.2629\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.9650 - mae: 14.9650\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.2862 - mae: 15.2862\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 19.1086 - mae: 19.1086\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 29.8229 - mae: 29.8229\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.1742 - mae: 10.1742\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.5240 - mae: 21.5240\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.5716 - mae: 10.5716\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.3977 - mae: 18.3977\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.4138 - mae: 7.4138\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.7380 - mae: 17.7380\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.1144 - mae: 11.1144\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 19.4346 - mae: 19.4346\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.1593 - mae: 12.1593\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.5653 - mae: 11.5653\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.8827 - mae: 13.8827\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 20.2277 - mae: 20.2277\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6b83159050>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "5xOQt5Zw3p56",
        "outputId": "e99aecd6-09d7-4ac0-9d07-4df228017cd1"
      },
      "source": [
        "# Make and plot predictions for model_1\n",
        "y_preds_2 = model_2.predict(X_test)\n",
        "plot_predictions(predictions=y_preds_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws8L2UrI3v15",
        "outputId": "30e4907d-f4ac-4bc7-d4eb-a1563cbdcf47"
      },
      "source": [
        "# Calculate model_2 metrics\n",
        "mae_2 = mae(y_test, y_preds_2)\n",
        "mse_2 = mse(y_test, y_preds_2)\n",
        "mae_2, mse_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=3.1969407>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=13.070143>)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA2mwdvg4NOG"
      },
      "source": [
        "#### **Build `model_3`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyRHDhz83zNC",
        "outputId": "e2fc6ad7-c7bb-4254-8a49-55ac955c9335"
      },
      "source": [
        "# Let's create a model which builds automatically by defining the input_shape argument\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_3 = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(10),\n",
        "                             tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_3.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model\n",
        "model_3.fit(X_train, y_train, epochs=500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 27.4058 - mae: 27.4058\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 24.6339 - mae: 24.6339\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 29.8935 - mae: 29.8935\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 27.4055 - mae: 27.4055\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.9463 - mae: 14.9463\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.8819 - mae: 11.8819\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.1988 - mae: 11.1988\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.0910 - mae: 11.0910\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 40.4763 - mae: 40.4763\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 27.8688 - mae: 27.8688\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.2473 - mae: 10.2473\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 25.2803 - mae: 25.2803\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.9897 - mae: 16.9897\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.9217 - mae: 25.9217\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.9948 - mae: 17.9948\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.3510 - mae: 7.3510\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.8636 - mae: 10.8636\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 19.5304 - mae: 19.5304\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.3469 - mae: 10.3469\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 17.6985 - mae: 17.6985\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.8984 - mae: 15.8984\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.1991 - mae: 14.1991\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.7720 - mae: 8.7720\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11.0570 - mae: 11.0570\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.6838 - mae: 12.6838\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 26.1877 - mae: 26.1877\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.7432 - mae: 11.7432\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22.8730 - mae: 22.8730\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.2459 - mae: 9.2459\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 29.2641 - mae: 29.2641\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 53.0225 - mae: 53.0225\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.9951 - mae: 11.9951\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.6357 - mae: 15.6357\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.6925 - mae: 12.6925\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2398 - mae: 9.2398\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.6497 - mae: 16.6497\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.0382 - mae: 11.0382\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 18.1634 - mae: 18.1634\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 19.1013 - mae: 19.1013\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 20.4324 - mae: 20.4324\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.9102 - mae: 14.9102\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.2809 - mae: 12.2809\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.7333 - mae: 10.7333\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.0260 - mae: 23.0260\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.3897 - mae: 10.3897\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.7904 - mae: 11.7904\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.6438 - mae: 9.6438\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.2335 - mae: 17.2335\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.5729 - mae: 9.5729\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.8185 - mae: 13.8185\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.5958 - mae: 11.5958\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 30.5538 - mae: 30.5538\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.3541 - mae: 14.3541\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.9713 - mae: 23.9713\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.1938 - mae: 23.1938\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 10.8837 - mae: 10.8837\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.7445 - mae: 12.7445\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.5995 - mae: 9.5995\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.5172 - mae: 12.5172\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.3200 - mae: 12.3200\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.4604 - mae: 17.4604\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.6052 - mae: 10.6052\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.4893 - mae: 10.4893\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 24.8450 - mae: 24.8450\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.6761 - mae: 10.6761\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 21.7809 - mae: 21.7809\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.7136 - mae: 10.7136\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.6397 - mae: 10.6397\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 22.6914 - mae: 22.6914\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 9.3316 - mae: 9.3316\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.4355 - mae: 15.4355\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.7437 - mae: 6.7437\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.6891 - mae: 11.6891\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24.0400 - mae: 24.0400\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.5896 - mae: 9.5896\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.4371 - mae: 12.4371\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.6489 - mae: 16.6489\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.0614 - mae: 9.0614\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.9675 - mae: 23.9675\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 26.7463 - mae: 26.7463\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.6714 - mae: 11.6714\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 12.0228 - mae: 12.0228\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.4218 - mae: 17.4218\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.2629 - mae: 7.2629\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.9650 - mae: 14.9650\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.2862 - mae: 15.2862\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 19.1086 - mae: 19.1086\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 29.8229 - mae: 29.8229\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.1742 - mae: 10.1742\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 21.5240 - mae: 21.5240\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.5716 - mae: 10.5716\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.3977 - mae: 18.3977\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.4138 - mae: 7.4138\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.7380 - mae: 17.7380\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 11.1144 - mae: 11.1144\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 19.4346 - mae: 19.4346\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.1593 - mae: 12.1593\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.5653 - mae: 11.5653\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.8827 - mae: 13.8827\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 20.2277 - mae: 20.2277\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.4479 - mae: 11.4479\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.4842 - mae: 17.4842\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.0217 - mae: 7.0217\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.5789 - mae: 23.5789\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.8932 - mae: 16.8932\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2954 - mae: 9.2954\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.3749 - mae: 25.3749\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.4621 - mae: 13.4621\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.5238 - mae: 9.5238\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.6722 - mae: 9.6722\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.5987 - mae: 14.5987\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.5670 - mae: 9.5670\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.8092 - mae: 17.8092\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.1782 - mae: 17.1782\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.1182 - mae: 11.1182\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.3071 - mae: 23.3071\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.6144 - mae: 9.6144\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.6899 - mae: 10.6899\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.0355 - mae: 8.0355\n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 29.6859 - mae: 29.6859\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.0714 - mae: 8.0714\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 28.3086 - mae: 28.3086\n",
            "Epoch 123/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 32.9014 - mae: 32.9014\n",
            "Epoch 124/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 19.6291 - mae: 19.6291\n",
            "Epoch 125/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.0095 - mae: 7.0095\n",
            "Epoch 126/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 21.8056 - mae: 21.8056\n",
            "Epoch 127/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 7.9812 - mae: 7.9812\n",
            "Epoch 128/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 21.0585 - mae: 21.0585\n",
            "Epoch 129/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9.0107 - mae: 9.0107\n",
            "Epoch 130/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 24.0502 - mae: 24.0502\n",
            "Epoch 131/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.7537 - mae: 9.7537\n",
            "Epoch 132/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 18.3052 - mae: 18.3052\n",
            "Epoch 133/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.5833 - mae: 7.5833\n",
            "Epoch 134/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.5755 - mae: 18.5755\n",
            "Epoch 135/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.5360 - mae: 10.5360\n",
            "Epoch 136/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.2694 - mae: 18.2694\n",
            "Epoch 137/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 23.1658 - mae: 23.1658\n",
            "Epoch 138/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.1362 - mae: 9.1362\n",
            "Epoch 139/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.9181 - mae: 8.9181\n",
            "Epoch 140/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.4732 - mae: 16.4732\n",
            "Epoch 141/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.4208 - mae: 8.4208\n",
            "Epoch 142/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 36.9540 - mae: 36.9540\n",
            "Epoch 143/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 25.5820 - mae: 25.5820\n",
            "Epoch 144/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.5392 - mae: 9.5392\n",
            "Epoch 145/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 26.6058 - mae: 26.6058\n",
            "Epoch 146/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.7248 - mae: 8.7248\n",
            "Epoch 147/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.6172 - mae: 15.6172\n",
            "Epoch 148/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 18.3065 - mae: 18.3065\n",
            "Epoch 149/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.1994 - mae: 8.1994\n",
            "Epoch 150/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4964 - mae: 7.4964\n",
            "Epoch 151/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.3374 - mae: 18.3374\n",
            "Epoch 152/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.2895 - mae: 10.2895\n",
            "Epoch 153/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 29.6425 - mae: 29.6425\n",
            "Epoch 154/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 10.5556 - mae: 10.5556\n",
            "Epoch 155/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.4537 - mae: 15.4537\n",
            "Epoch 156/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.0174 - mae: 17.0174\n",
            "Epoch 157/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 32.8218 - mae: 32.8218\n",
            "Epoch 158/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.7038 - mae: 10.7038\n",
            "Epoch 159/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.9054 - mae: 8.9054\n",
            "Epoch 160/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 22.1321 - mae: 22.1321\n",
            "Epoch 161/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 11.7113 - mae: 11.7113\n",
            "Epoch 162/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.5734 - mae: 21.5734\n",
            "Epoch 163/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 19.2485 - mae: 19.2485\n",
            "Epoch 164/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 11.0156 - mae: 11.0156\n",
            "Epoch 165/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.6187 - mae: 9.6187\n",
            "Epoch 166/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 21.5908 - mae: 21.5908\n",
            "Epoch 167/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 26.2851 - mae: 26.2851\n",
            "Epoch 168/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.8525 - mae: 9.8525\n",
            "Epoch 169/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 22.5630 - mae: 22.5630\n",
            "Epoch 170/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 10.1499 - mae: 10.1499\n",
            "Epoch 171/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 18.0464 - mae: 18.0464\n",
            "Epoch 172/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 28.8377 - mae: 28.8377\n",
            "Epoch 173/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.5279 - mae: 16.5279\n",
            "Epoch 174/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.2115 - mae: 11.2115\n",
            "Epoch 175/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 27.5839 - mae: 27.5839\n",
            "Epoch 176/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.2680 - mae: 8.2680\n",
            "Epoch 177/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.2580 - mae: 9.2580\n",
            "Epoch 178/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.1440 - mae: 18.1440\n",
            "Epoch 179/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.5995 - mae: 10.5995\n",
            "Epoch 180/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.8992 - mae: 7.8992\n",
            "Epoch 181/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.4015 - mae: 17.4015\n",
            "Epoch 182/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 11.0089 - mae: 11.0089\n",
            "Epoch 183/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.7027 - mae: 11.7027\n",
            "Epoch 184/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 30.4062 - mae: 30.4062\n",
            "Epoch 185/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.5557 - mae: 7.5557\n",
            "Epoch 186/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 15.9905 - mae: 15.9905\n",
            "Epoch 187/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.5579 - mae: 8.5579\n",
            "Epoch 188/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 28.7339 - mae: 28.7339\n",
            "Epoch 189/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.1689 - mae: 13.1689\n",
            "Epoch 190/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.3101 - mae: 18.3101\n",
            "Epoch 191/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.7376 - mae: 13.7376\n",
            "Epoch 192/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.7104 - mae: 13.7104\n",
            "Epoch 193/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 28.5842 - mae: 28.5842\n",
            "Epoch 194/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 7.0707 - mae: 7.0707\n",
            "Epoch 195/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.0550 - mae: 7.0550\n",
            "Epoch 196/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 22.0067 - mae: 22.0067\n",
            "Epoch 197/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 20.8443 - mae: 20.8443\n",
            "Epoch 198/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.4713 - mae: 12.4713\n",
            "Epoch 199/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.9099 - mae: 17.9099\n",
            "Epoch 200/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.7494 - mae: 13.7494\n",
            "Epoch 201/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.4687 - mae: 5.4687\n",
            "Epoch 202/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.7006 - mae: 13.7006\n",
            "Epoch 203/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.4142 - mae: 9.4142\n",
            "Epoch 204/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 20.9796 - mae: 20.9796\n",
            "Epoch 205/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.5470 - mae: 9.5470\n",
            "Epoch 206/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.7256 - mae: 11.7256\n",
            "Epoch 207/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 14.3772 - mae: 14.3772\n",
            "Epoch 208/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.8579 - mae: 14.8579\n",
            "Epoch 209/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.9706 - mae: 14.9706\n",
            "Epoch 210/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 17.8998 - mae: 17.8998\n",
            "Epoch 211/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.8327 - mae: 9.8327\n",
            "Epoch 212/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.3352 - mae: 18.3352\n",
            "Epoch 213/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.0383 - mae: 15.0383\n",
            "Epoch 214/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.5874 - mae: 14.5874\n",
            "Epoch 215/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.3015 - mae: 23.3015\n",
            "Epoch 216/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.3613 - mae: 13.3613\n",
            "Epoch 217/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.8517 - mae: 9.8517\n",
            "Epoch 218/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.5451 - mae: 12.5451\n",
            "Epoch 219/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.9472 - mae: 4.9472\n",
            "Epoch 220/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.1130 - mae: 7.1130\n",
            "Epoch 221/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 35.4567 - mae: 35.4567\n",
            "Epoch 222/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 34.8634 - mae: 34.8634\n",
            "Epoch 223/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.9846 - mae: 7.9846\n",
            "Epoch 224/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 14.7004 - mae: 14.7004\n",
            "Epoch 225/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.7196 - mae: 16.7196\n",
            "Epoch 226/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.9329 - mae: 15.9329\n",
            "Epoch 227/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.1644 - mae: 16.1644\n",
            "Epoch 228/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.9324 - mae: 13.9324\n",
            "Epoch 229/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 18.0504 - mae: 18.0504\n",
            "Epoch 230/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 15.6120 - mae: 15.6120\n",
            "Epoch 231/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 21.2041 - mae: 21.2041\n",
            "Epoch 232/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 25.2732 - mae: 25.2732\n",
            "Epoch 233/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 16.3176 - mae: 16.3176\n",
            "Epoch 234/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.2729 - mae: 7.2729\n",
            "Epoch 235/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.9688 - mae: 16.9688\n",
            "Epoch 236/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.1225 - mae: 7.1225\n",
            "Epoch 237/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.2058 - mae: 9.2058\n",
            "Epoch 238/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 8.0961 - mae: 8.0961\n",
            "Epoch 239/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.0538 - mae: 17.0538\n",
            "Epoch 240/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.8627 - mae: 8.8627\n",
            "Epoch 241/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 13.1711 - mae: 13.1711\n",
            "Epoch 242/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.7886 - mae: 8.7886\n",
            "Epoch 243/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.8161 - mae: 18.8161\n",
            "Epoch 244/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.0531 - mae: 14.0531\n",
            "Epoch 245/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.6831 - mae: 14.6831\n",
            "Epoch 246/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.8045 - mae: 15.8045\n",
            "Epoch 247/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.6810 - mae: 17.6810\n",
            "Epoch 248/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.2367 - mae: 13.2367\n",
            "Epoch 249/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.5070 - mae: 14.5070\n",
            "Epoch 250/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.2322 - mae: 23.2322\n",
            "Epoch 251/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.3009 - mae: 9.3009\n",
            "Epoch 252/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 36.6569 - mae: 36.6569\n",
            "Epoch 253/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 21.8205 - mae: 21.8205\n",
            "Epoch 254/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.2792 - mae: 7.2792\n",
            "Epoch 255/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 24.7127 - mae: 24.7127\n",
            "Epoch 256/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.4220 - mae: 12.4220\n",
            "Epoch 257/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.5823 - mae: 10.5823\n",
            "Epoch 258/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.4883 - mae: 14.4883\n",
            "Epoch 259/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 8.6132 - mae: 8.6132\n",
            "Epoch 260/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 43.0580 - mae: 43.0580\n",
            "Epoch 261/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.4611 - mae: 18.4611\n",
            "Epoch 262/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6.8820 - mae: 6.8820\n",
            "Epoch 263/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.7211 - mae: 13.7211\n",
            "Epoch 264/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 21.0154 - mae: 21.0154\n",
            "Epoch 265/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 19.3731 - mae: 19.3731\n",
            "Epoch 266/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.4735 - mae: 11.4735\n",
            "Epoch 267/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5302 - mae: 7.5302\n",
            "Epoch 268/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 21.6453 - mae: 21.6453\n",
            "Epoch 269/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 33.1785 - mae: 33.1785\n",
            "Epoch 270/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.0833 - mae: 10.0833\n",
            "Epoch 271/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.1012 - mae: 12.1012\n",
            "Epoch 272/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 26.1372 - mae: 26.1372\n",
            "Epoch 273/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.1751 - mae: 12.1751\n",
            "Epoch 274/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.3272 - mae: 13.3272\n",
            "Epoch 275/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 29.3775 - mae: 29.3775\n",
            "Epoch 276/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.3329 - mae: 7.3329\n",
            "Epoch 277/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 31.1362 - mae: 31.1362\n",
            "Epoch 278/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.3015 - mae: 12.3015\n",
            "Epoch 279/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.4103 - mae: 16.4103\n",
            "Epoch 280/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 21.9118 - mae: 21.9118\n",
            "Epoch 281/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 22.1501 - mae: 22.1501\n",
            "Epoch 282/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.7429 - mae: 7.7429\n",
            "Epoch 283/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.1429 - mae: 8.1429\n",
            "Epoch 284/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 24.9435 - mae: 24.9435\n",
            "Epoch 285/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.6958 - mae: 13.6958\n",
            "Epoch 286/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.8926 - mae: 6.8926\n",
            "Epoch 287/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 24.5352 - mae: 24.5352\n",
            "Epoch 288/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 20.1721 - mae: 20.1721\n",
            "Epoch 289/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11.9658 - mae: 11.9658\n",
            "Epoch 290/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.5391 - mae: 16.5391\n",
            "Epoch 291/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.8017 - mae: 16.8017\n",
            "Epoch 292/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.4642 - mae: 9.4642\n",
            "Epoch 293/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.2711 - mae: 15.2711\n",
            "Epoch 294/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22.7179 - mae: 22.7179\n",
            "Epoch 295/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.9234 - mae: 17.9234\n",
            "Epoch 296/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.1743 - mae: 6.1743\n",
            "Epoch 297/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.9440 - mae: 10.9440\n",
            "Epoch 298/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.1530 - mae: 23.1530\n",
            "Epoch 299/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.7331 - mae: 17.7331\n",
            "Epoch 300/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.9824 - mae: 6.9824\n",
            "Epoch 301/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.1857 - mae: 25.1857\n",
            "Epoch 302/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.9025 - mae: 8.9025\n",
            "Epoch 303/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 17.7668 - mae: 17.7668\n",
            "Epoch 304/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11.0002 - mae: 11.0002\n",
            "Epoch 305/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.9191 - mae: 12.9191\n",
            "Epoch 306/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.4033 - mae: 8.4033\n",
            "Epoch 307/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.6094 - mae: 13.6094\n",
            "Epoch 308/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.4404 - mae: 7.4404\n",
            "Epoch 309/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.4642 - mae: 9.4642\n",
            "Epoch 310/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.7099 - mae: 10.7099\n",
            "Epoch 311/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.2814 - mae: 13.2814\n",
            "Epoch 312/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 29.9763 - mae: 29.9763\n",
            "Epoch 313/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6304 - mae: 7.6304\n",
            "Epoch 314/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.9106 - mae: 9.9106\n",
            "Epoch 315/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 23.7669 - mae: 23.7669\n",
            "Epoch 316/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.3937 - mae: 16.3937\n",
            "Epoch 317/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 21.0758 - mae: 21.0758\n",
            "Epoch 318/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.9367 - mae: 7.9367\n",
            "Epoch 319/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.9731 - mae: 17.9731\n",
            "Epoch 320/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.2375 - mae: 10.2375\n",
            "Epoch 321/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.3338 - mae: 8.3338\n",
            "Epoch 322/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.0621 - mae: 5.0621\n",
            "Epoch 323/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.5109 - mae: 23.5109\n",
            "Epoch 324/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.8309 - mae: 6.8309\n",
            "Epoch 325/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.3863 - mae: 16.3863\n",
            "Epoch 326/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5019 - mae: 7.5019\n",
            "Epoch 327/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 20.0573 - mae: 20.0573\n",
            "Epoch 328/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.7661 - mae: 13.7661\n",
            "Epoch 329/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.8282 - mae: 16.8282\n",
            "Epoch 330/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.0514 - mae: 7.0514\n",
            "Epoch 331/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 21.4846 - mae: 21.4846\n",
            "Epoch 332/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.2880 - mae: 12.2880\n",
            "Epoch 333/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.8117 - mae: 11.8117\n",
            "Epoch 334/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.3600 - mae: 8.3600\n",
            "Epoch 335/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 12.4833 - mae: 12.4833\n",
            "Epoch 336/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 32.2171 - mae: 32.2171\n",
            "Epoch 337/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 10.4477 - mae: 10.4477\n",
            "Epoch 338/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 19.6832 - mae: 19.6832\n",
            "Epoch 339/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 35.0762 - mae: 35.0762\n",
            "Epoch 340/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 10.4192 - mae: 10.4192\n",
            "Epoch 341/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.7625 - mae: 9.7625\n",
            "Epoch 342/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.9500 - mae: 11.9500\n",
            "Epoch 343/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.3943 - mae: 9.3943\n",
            "Epoch 344/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.6071 - mae: 5.6071\n",
            "Epoch 345/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 37.4876 - mae: 37.4876\n",
            "Epoch 346/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.8830 - mae: 16.8830\n",
            "Epoch 347/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.8748 - mae: 12.8748\n",
            "Epoch 348/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.1960 - mae: 8.1960\n",
            "Epoch 349/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.5568 - mae: 13.5568\n",
            "Epoch 350/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 15.4354 - mae: 15.4354\n",
            "Epoch 351/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 32.9626 - mae: 32.9626\n",
            "Epoch 352/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.2040 - mae: 14.2040\n",
            "Epoch 353/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.9196 - mae: 15.9196\n",
            "Epoch 354/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 19.0878 - mae: 19.0878\n",
            "Epoch 355/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 34.1178 - mae: 34.1178\n",
            "Epoch 356/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.6798 - mae: 7.6798\n",
            "Epoch 357/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 25.2287 - mae: 25.2287\n",
            "Epoch 358/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 22.6759 - mae: 22.6759\n",
            "Epoch 359/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.8765 - mae: 8.8765\n",
            "Epoch 360/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 21.4709 - mae: 21.4709\n",
            "Epoch 361/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 20.6073 - mae: 20.6073\n",
            "Epoch 362/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.0611 - mae: 7.0611\n",
            "Epoch 363/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 25.8117 - mae: 25.8117\n",
            "Epoch 364/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 32.2247 - mae: 32.2247\n",
            "Epoch 365/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.0204 - mae: 10.0204\n",
            "Epoch 366/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.6722 - mae: 9.6722\n",
            "Epoch 367/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 30.4171 - mae: 30.4171\n",
            "Epoch 368/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.5020 - mae: 10.5020\n",
            "Epoch 369/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 14.9909 - mae: 14.9909\n",
            "Epoch 370/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.6580 - mae: 14.6580\n",
            "Epoch 371/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 23.3672 - mae: 23.3672\n",
            "Epoch 372/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.1025 - mae: 13.1025\n",
            "Epoch 373/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.2586 - mae: 9.2586\n",
            "Epoch 374/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.6648 - mae: 9.6648\n",
            "Epoch 375/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.0041 - mae: 13.0041\n",
            "Epoch 376/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.8863 - mae: 14.8863\n",
            "Epoch 377/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.7932 - mae: 14.7932\n",
            "Epoch 378/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.2751 - mae: 16.2751\n",
            "Epoch 379/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 20.8307 - mae: 20.8307\n",
            "Epoch 380/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 33.5317 - mae: 33.5317\n",
            "Epoch 381/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.2166 - mae: 8.2166\n",
            "Epoch 382/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 13.0960 - mae: 13.0960\n",
            "Epoch 383/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.3999 - mae: 8.3999\n",
            "Epoch 384/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.1283 - mae: 7.1283\n",
            "Epoch 385/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.9390 - mae: 10.9390\n",
            "Epoch 386/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.7654 - mae: 19.7654\n",
            "Epoch 387/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 24.8625 - mae: 24.8625\n",
            "Epoch 388/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.7422 - mae: 8.7422\n",
            "Epoch 389/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.9488 - mae: 5.9488\n",
            "Epoch 390/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 24.4400 - mae: 24.4400\n",
            "Epoch 391/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.9771 - mae: 5.9771\n",
            "Epoch 392/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.3250 - mae: 16.3250\n",
            "Epoch 393/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.0917 - mae: 6.0917\n",
            "Epoch 394/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.0963 - mae: 11.0963\n",
            "Epoch 395/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 14.9601 - mae: 14.9601\n",
            "Epoch 396/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 7.6462 - mae: 7.6462\n",
            "Epoch 397/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.7654 - mae: 8.7654\n",
            "Epoch 398/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.5991 - mae: 14.5991\n",
            "Epoch 399/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.3166 - mae: 11.3166\n",
            "Epoch 400/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 21.9080 - mae: 21.9080\n",
            "Epoch 401/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.8653 - mae: 14.8653\n",
            "Epoch 402/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.4970 - mae: 8.4970\n",
            "Epoch 403/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.3957 - mae: 10.3957\n",
            "Epoch 404/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.2556 - mae: 10.2556\n",
            "Epoch 405/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.3392 - mae: 6.3392\n",
            "Epoch 406/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 17.4602 - mae: 17.4602\n",
            "Epoch 407/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.4627 - mae: 11.4627\n",
            "Epoch 408/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 20.7294 - mae: 20.7294\n",
            "Epoch 409/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 31.3338 - mae: 31.3338\n",
            "Epoch 410/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2542 - mae: 9.2542\n",
            "Epoch 411/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.8621 - mae: 14.8621\n",
            "Epoch 412/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 21.7182 - mae: 21.7182\n",
            "Epoch 413/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.6615 - mae: 12.6615\n",
            "Epoch 414/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.0687 - mae: 6.0687\n",
            "Epoch 415/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.2201 - mae: 13.2201\n",
            "Epoch 416/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 27.4244 - mae: 27.4244\n",
            "Epoch 417/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.6407 - mae: 10.6407\n",
            "Epoch 418/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.8230 - mae: 12.8230\n",
            "Epoch 419/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.8836 - mae: 15.8836\n",
            "Epoch 420/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24.7510 - mae: 24.7510\n",
            "Epoch 421/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 17.3753 - mae: 17.3753\n",
            "Epoch 422/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.8241 - mae: 7.8241\n",
            "Epoch 423/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.3789 - mae: 25.3789\n",
            "Epoch 424/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.1031 - mae: 15.1031\n",
            "Epoch 425/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.1643 - mae: 7.1643\n",
            "Epoch 426/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 20.3318 - mae: 20.3318\n",
            "Epoch 427/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.3283 - mae: 6.3283\n",
            "Epoch 428/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.9961 - mae: 12.9961\n",
            "Epoch 429/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.7869 - mae: 10.7869\n",
            "Epoch 430/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.4007 - mae: 11.4007\n",
            "Epoch 431/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 10.6152 - mae: 10.6152\n",
            "Epoch 432/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.4582 - mae: 11.4582\n",
            "Epoch 433/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.3851 - mae: 11.3851\n",
            "Epoch 434/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 30.3986 - mae: 30.3986\n",
            "Epoch 435/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.5052 - mae: 10.5052\n",
            "Epoch 436/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 28.8810 - mae: 28.8810\n",
            "Epoch 437/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.5916 - mae: 8.5916\n",
            "Epoch 438/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.7378 - mae: 12.7378\n",
            "Epoch 439/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 33.6754 - mae: 33.6754\n",
            "Epoch 440/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.0963 - mae: 15.0963\n",
            "Epoch 441/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.4813 - mae: 17.4813\n",
            "Epoch 442/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 22.3049 - mae: 22.3049\n",
            "Epoch 443/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 23.5841 - mae: 23.5841\n",
            "Epoch 444/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.0008 - mae: 11.0008\n",
            "Epoch 445/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.9175 - mae: 14.9175\n",
            "Epoch 446/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.9979 - mae: 17.9979\n",
            "Epoch 447/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.4482 - mae: 5.4482\n",
            "Epoch 448/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.0527 - mae: 10.0527\n",
            "Epoch 449/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 14.0052 - mae: 14.0052\n",
            "Epoch 450/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.7782 - mae: 16.7782\n",
            "Epoch 451/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.2937 - mae: 14.2937\n",
            "Epoch 452/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 30.6193 - mae: 30.6193\n",
            "Epoch 453/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.6541 - mae: 7.6541\n",
            "Epoch 454/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 28.1428 - mae: 28.1428\n",
            "Epoch 455/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8.0017 - mae: 8.0017\n",
            "Epoch 456/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.3933 - mae: 10.3933\n",
            "Epoch 457/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.0242 - mae: 15.0242\n",
            "Epoch 458/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.5653 - mae: 16.5653\n",
            "Epoch 459/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 26.8566 - mae: 26.8566\n",
            "Epoch 460/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.4852 - mae: 12.4852\n",
            "Epoch 461/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.4784 - mae: 12.4784\n",
            "Epoch 462/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 13.3186 - mae: 13.3186\n",
            "Epoch 463/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 29.5524 - mae: 29.5524\n",
            "Epoch 464/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 3.4664 - mae: 3.4664\n",
            "Epoch 465/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 15.2136 - mae: 15.2136\n",
            "Epoch 466/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.8327 - mae: 20.8327\n",
            "Epoch 467/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 30.5108 - mae: 30.5108\n",
            "Epoch 468/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.0597 - mae: 11.0597\n",
            "Epoch 469/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.8372 - mae: 12.8372\n",
            "Epoch 470/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.2398 - mae: 3.2398\n",
            "Epoch 471/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 16.6964 - mae: 16.6964\n",
            "Epoch 472/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 13.3883 - mae: 13.3883\n",
            "Epoch 473/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.2771 - mae: 15.2771\n",
            "Epoch 474/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.7448 - mae: 11.7448\n",
            "Epoch 475/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.4113 - mae: 16.4113\n",
            "Epoch 476/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.8785 - mae: 13.8785\n",
            "Epoch 477/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 30.6702 - mae: 30.6702\n",
            "Epoch 478/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 8.5880 - mae: 8.5880\n",
            "Epoch 479/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.7384 - mae: 10.7384\n",
            "Epoch 480/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.9051 - mae: 17.9051\n",
            "Epoch 481/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.8095 - mae: 15.8095\n",
            "Epoch 482/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 21.3054 - mae: 21.3054\n",
            "Epoch 483/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25.3845 - mae: 25.3845\n",
            "Epoch 484/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.9815 - mae: 23.9815\n",
            "Epoch 485/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.7734 - mae: 5.7734\n",
            "Epoch 486/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 20.0010 - mae: 20.0010\n",
            "Epoch 487/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.0419 - mae: 14.0419\n",
            "Epoch 488/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 30.6088 - mae: 30.6088\n",
            "Epoch 489/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.9409 - mae: 11.9409\n",
            "Epoch 490/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.7352 - mae: 12.7352\n",
            "Epoch 491/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.6139 - mae: 23.6139\n",
            "Epoch 492/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.5365 - mae: 20.5365\n",
            "Epoch 493/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.9942 - mae: 4.9942\n",
            "Epoch 494/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.7986 - mae: 12.7986\n",
            "Epoch 495/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.3772 - mae: 13.3772\n",
            "Epoch 496/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 12.6727 - mae: 12.6727\n",
            "Epoch 497/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.6192 - mae: 17.6192\n",
            "Epoch 498/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 23.5629 - mae: 23.5629\n",
            "Epoch 499/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 9.3755 - mae: 9.3755\n",
            "Epoch 500/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.6316 - mae: 14.6316\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6b82f526d0>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "1TiBRuxQ4YlJ",
        "outputId": "08d6dc85-10ad-4500-ad5a-cce48f14753b"
      },
      "source": [
        "# Make and plot predictions for model_1\n",
        "y_preds_3 = model_3.predict(X_test)\n",
        "plot_predictions(predictions=y_preds_3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wcC_88V4yd7",
        "outputId": "36168b10-64b0-4186-c594-4ac4d06cae56"
      },
      "source": [
        "# Calculate model_2 metrics\n",
        "mae_3 = mae(y_test, y_preds_3)\n",
        "mse_3= mse(y_test, y_preds_3)\n",
        "mae_3, mse_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=68.713615>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=4808.0273>)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdFCNqNZ5Oz5"
      },
      "source": [
        " **Note:** You want to start with small experiments (small models) and make sure they work and then increase their scale when necessary \n",
        "\n",
        "> \"Experiments,Experiments,Experiments!!!!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vQhWM-g5L1_"
      },
      "source": [
        "### Comparing results\n",
        "\n",
        "We've run a few experiments, let's compare the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "BI8Scsxu5Huq",
        "outputId": "01f9e31d-8682-4adb-cfe0-ab85dc71c976"
      },
      "source": [
        "# Let's compare our model's results using a pandas DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "model_results = [[\"model_1\", mae_1.numpy(), mse_1.numpy()],\n",
        "                 [\"model_2\", mae_2.numpy(), mse_2.numpy()],\n",
        "                 [\"model_3\", mae_3.numpy(), mse_3.numpy()]]\n",
        "\n",
        "all_results = pd.DataFrame(model_results, columns=[\"model\", \"mae\", \"mse\"])\n",
        "all_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>mae</th>\n",
              "      <th>mse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>model_1</td>\n",
              "      <td>18.745327</td>\n",
              "      <td>353.573364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>model_2</td>\n",
              "      <td>3.196941</td>\n",
              "      <td>13.070143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>model_3</td>\n",
              "      <td>68.713615</td>\n",
              "      <td>4808.027344</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     model        mae          mse\n",
              "0  model_1  18.745327   353.573364\n",
              "1  model_2   3.196941    13.070143\n",
              "2  model_3  68.713615  4808.027344"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Wo6D27T6iI6"
      },
      "source": [
        "\n",
        "From our experiments, it looks like model_2 performed the best."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Z0anBFn6R4j",
        "outputId": "387c9fd0-aa31-4de3-d10d-01c4040394a6"
      },
      "source": [
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_14 (Dense)             (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgcDRbbL6lOO"
      },
      "source": [
        ">  **Note:** One of your main goals should be to minimize the time between your experiments. The more experiments you do, the more things you'll figure out which don't work and in turn, get closer to figuring out what does work. Remember the machine learning practitioner's motto: \"experiment, experiment, experiment\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6bB-2j-7EQh"
      },
      "source": [
        "## Tracking your experiments\n",
        "\n",
        "One really good habit to get into is tracking your modelling experiments to see which perform better than others.\n",
        "\n",
        "And when doing so, it can be tedious if you're running lots of experiments\n",
        "\n",
        "Luckily, there are tools to help us\n",
        "\n",
        " **Resource:** As you build more models, you'll want to look into using:\n",
        "* **[TensorBoard](https://tensorboard.dev/)** - a component of the TensorFlow library to help track modelling experiments (we'll see this later).\n",
        "* **[Weights & Biases](https://wandb.ai/site)** - a tool for tracking all kinds of machine learning experiments (the good news for Weights & Biases is it plugs into TensorBoard)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NjfnYmv76qZ"
      },
      "source": [
        "## Saving our models\n",
        "\n",
        "Saving our model allows us to use themoutside of Google Colab (or wherever they were trained) such as in a web application or a mobile app.\n",
        "\n",
        "There are two main formats we can save our model's too:\n",
        "1. The SavedModel format\n",
        "2. THe HDF5 format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpwE2TMA6WWp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a41095e7-5cdf-410b-9384-1b8cbedc6d0d"
      },
      "source": [
        "# Save model using the SavedModel format\n",
        "model_2.save(\"best_model_SaveModel_format\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best_model_SaveModel_format/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iHjMJFXVP-H"
      },
      "source": [
        "If you are staying in pure TensorFlow code, you are probably better off using the SaveFormat Method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI4gtJSrT00r"
      },
      "source": [
        "# Save model using the HDF5 format\n",
        "model_2.save(\"best_model_SaveModel_format.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmkHh74vVc_K"
      },
      "source": [
        "If you are going out from TensorFlow code, you are probably better off using the HDF5 Method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFo96iGiVwz-"
      },
      "source": [
        "### Loading a saved Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjLXSStDVkV_",
        "outputId": "68cba648-e310-44f3-9312-4c0ee5d63a3d"
      },
      "source": [
        "# Load in the SavedModel format model\n",
        "loaded_SavedModel_format = tf.keras.models.load_model(\"best_model_SaveModel_format\")\n",
        "loaded_SavedModel_format.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_14 (Dense)             (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BN3kv0BTWVEv",
        "outputId": "5f646685-5057-4e02-f885-b2dadfccb426"
      },
      "source": [
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_14 (Dense)             (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuPmG5B9Wk6N",
        "outputId": "128cd1c2-c064-4be6-a379-c4a0334e80c2"
      },
      "source": [
        "# Compare model_2 with the SavedModel version (should return True)\n",
        "model_2_preds =model_2.predict(X_test)\n",
        "loaded_SavedModel_format_preds = loaded_SavedModel_format.predict(X_test)\n",
        "model_2_preds == loaded_SavedModel_format_preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True]])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9y4tluPW7u-",
        "outputId": "49169e2c-d24e-4f22-b083-8200777fa862"
      },
      "source": [
        "mae(y_test, model_2_preds) == mae(y_test, loaded_SavedModel_format_preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYkgQfrOXfLn"
      },
      "source": [
        "# Load in a model using the .h6 format\n",
        "loaded_h5_model = tf.keras.models.load_model(\"best_model_SaveModel_format.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YG-SxESpYYgi",
        "outputId": "5338b2e6-3f8a-4cef-e41b-ef2f2caf38ae"
      },
      "source": [
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_14 (Dense)             (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjVRs-6aYavW",
        "outputId": "5809ac98-9097-48cd-89a2-688bc6cf5ffe"
      },
      "source": [
        "# Compare model_2 with the .h5 version (should return True)\n",
        "model_2_preds =model_2.predict(X_test)\n",
        "loaded_h5_format_preds = loaded_h5_model.predict(X_test)\n",
        "model_2_preds == loaded_h5_format_preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True]])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO59nlyyY7Cu"
      },
      "source": [
        "## Downloading a model or any other file from Google Colab\n",
        "\n",
        "If you want to download your files from Google Colab:\n",
        "\n",
        "1. You can go to \"files\" tab and right click on the file you're after and click 'download'.\n",
        "2. Use Code (see the cell below).\n",
        "3. Save it to Google Drive by connecting to Gogle Drive and copying it there (See 2nd code cell below)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "9Zx40CTZYoGX",
        "outputId": "002ef42e-1384-4425-aceb-3bd9ed175cc7"
      },
      "source": [
        "# Download a file from Google Colab\n",
        "from google.colab import files\n",
        "files.download(\"/content/best_model_SaveModel_format.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_2550ff54-7a7b-4fc4-92e6-c54dd88aca2e\", \"best_model_SaveModel_format.h5\", 17040)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFGF2QURZ21X"
      },
      "source": [
        "# Save a file from Google Colab to Google Drive (Requires mounting Google Drive)\n",
        "!cp /content/best_model_SaveModel_format.h5 /content/drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZ3iJIQiaiwx",
        "outputId": "03b5693c-e029-4661-c612-1e889b15bb33"
      },
      "source": [
        "!ls /content/drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " best_model_SaveModel_format.h5  'Google Earth'\n",
            "'Colab Notebooks'\t\t 'Thesis Improved (71321).docx'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8ftkbzXa4Us"
      },
      "source": [
        "## A Larger Example\n",
        "\n",
        "Let's step it up a notch and build a model for a more feature rich datase.\n",
        "\n",
        "More specifically we're going to try predict the cost of medical insurance for individuals based on a number of different parameters such as, age, sex, bmi, children, smoking_status and residential_region.\n",
        "\n",
        "The link to the dataset is in [Kaggle's Medical Cost Personal Datasets](https://www.kaggle.com/mirichoi0218/insurance) and the raw dataset of the insurance is hosted on [Github](https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv)\n",
        "\n",
        ">  **Note:** When learning machine learning paradigms, you'll often go through a series of foundational techniques and then practice them by working with open-source datasets and examples. Just as we're doing now, learn foundations, put them to work with different problems. Every time you work on something new, it's a good idea to search for something like \"problem X example with Python/TensorFlow\" where you substitute X for your problem.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo7xutElalBe"
      },
      "source": [
        "# Import required libraries\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "DImC_xiUb_eR",
        "outputId": "08b4aa77-59f7-4546-d55f-e157c29c2727"
      },
      "source": [
        "# Read in the insurance dataset and check the dataset\n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
        "insurance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows  7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     sex     bmi  children smoker     region      charges\n",
              "0      19  female  27.900         0    yes  southwest  16884.92400\n",
              "1      18    male  33.770         1     no  southeast   1725.55230\n",
              "2      28    male  33.000         3     no  southeast   4449.46200\n",
              "3      33    male  22.705         0     no  northwest  21984.47061\n",
              "4      32    male  28.880         0     no  northwest   3866.85520\n",
              "...   ...     ...     ...       ...    ...        ...          ...\n",
              "1333   50    male  30.970         3     no  northwest  10600.54830\n",
              "1334   18  female  31.920         0     no  northeast   2205.98080\n",
              "1335   18  female  36.850         0     no  southeast   1629.83350\n",
              "1336   21  female  25.800         0     no  southwest   2007.94500\n",
              "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
              "\n",
              "[1338 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Xc7ezvwc2Fl"
      },
      "source": [
        "We can see from the above that some of our data are objects and some are numerical values. In ML, we first have to convert our objects to numerical values meaning we have to do `one-hot encoding`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "C5eE60NMcrZ3",
        "outputId": "3cf6028e-392f-4c1e-d4c2-7b85a65a7c93"
      },
      "source": [
        "# Let's try one-hot encode our DataFrame so it's all numbers\n",
        "insurance_one_hot = pd.get_dummies(insurance)\n",
        "insurance_one_hot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>charges</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>16884.92400</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>1725.55230</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>4449.46200</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>21984.47061</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>3866.85520</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>10600.54830</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>2205.98080</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>1629.83350</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>2007.94500</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>29141.36030</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows  12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     bmi  ...  region_southeast  region_southwest\n",
              "0      19  27.900  ...                 0                 1\n",
              "1      18  33.770  ...                 1                 0\n",
              "2      28  33.000  ...                 1                 0\n",
              "3      33  22.705  ...                 0                 0\n",
              "4      32  28.880  ...                 0                 0\n",
              "...   ...     ...  ...               ...               ...\n",
              "1333   50  30.970  ...                 0                 0\n",
              "1334   18  31.920  ...                 0                 0\n",
              "1335   18  36.850  ...                 1                 0\n",
              "1336   21  25.800  ...                 0                 1\n",
              "1337   61  29.070  ...                 0                 0\n",
              "\n",
              "[1338 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XuDSSAZ4eRgf",
        "outputId": "823da100-2e2d-445d-ab6f-bd181997b90a"
      },
      "source": [
        "# Create X & y values (features and labels)\n",
        "X = insurance_one_hot.drop(\"charges\", axis=1)\n",
        "y = insurance_one_hot[\"charges\"]\n",
        "\n",
        "# View X\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     bmi  children  ...  region_northwest  region_southeast  region_southwest\n",
              "0   19  27.900         0  ...                 0                 0                 1\n",
              "1   18  33.770         1  ...                 0                 1                 0\n",
              "2   28  33.000         3  ...                 0                 1                 0\n",
              "3   33  22.705         0  ...                 1                 0                 0\n",
              "4   32  28.880         0  ...                 1                 0                 0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXWIgqZWfe1s",
        "outputId": "8c4a4675-26a3-477a-ac46-a6244a84ded6"
      },
      "source": [
        "# View y\n",
        "y.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    16884.92400\n",
              "1     1725.55230\n",
              "2     4449.46200\n",
              "3    21984.47061\n",
              "4     3866.85520\n",
              "Name: charges, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmoU6bcgf67e",
        "outputId": "3788ac41-dd05-4b0b-8045-b7bed98cef0c"
      },
      "source": [
        "# Create training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "len(X), len(X_train), len(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1338, 1070, 268)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HsEGIeaff8X",
        "outputId": "1eadb62b-52af-4760-eaf3-b1e8b8c4aaf3"
      },
      "source": [
        "# Build a neuaral network\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1.Create a model\n",
        "insurance_model = tf.keras.Sequential([\n",
        "                                       tf.keras.layers.Dense(10),\n",
        "                                       tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model.compile(loss=tf.keras.losses.mae,\n",
        "                        optimizer=tf.keras.optimizers.SGD(),\n",
        "                        metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "insurance_model.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8637.1006 - mae: 8637.1006\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7886.7759 - mae: 7886.7759\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7558.1470 - mae: 7558.1470\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7792.0220 - mae: 7792.0220\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7748.3887 - mae: 7748.3887\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7595.3940 - mae: 7595.3940\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7589.9844 - mae: 7589.9844\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7698.5576 - mae: 7698.5576\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7496.7778 - mae: 7496.7778\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7493.1743 - mae: 7493.1743\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7769.7295 - mae: 7769.7295\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7706.9028 - mae: 7706.9028\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7687.7231 - mae: 7687.7231\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7689.9004 - mae: 7689.9004\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7393.5327 - mae: 7393.5327\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7780.6987 - mae: 7780.6987\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7578.5098 - mae: 7578.5098\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7750.8354 - mae: 7750.8354\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7739.2144 - mae: 7739.2144\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7875.0654 - mae: 7875.0654\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7466.6768 - mae: 7466.6768\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7941.2329 - mae: 7941.2329\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7640.2725 - mae: 7640.2725\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7539.2671 - mae: 7539.2671\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7619.9653 - mae: 7619.9653\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7644.1719 - mae: 7644.1719\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7709.0371 - mae: 7709.0371\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7366.8662 - mae: 7366.8662\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7444.3154 - mae: 7444.3154\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7616.4077 - mae: 7616.4077\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7686.3853 - mae: 7686.3853\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7548.0977 - mae: 7548.0977\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7501.5532 - mae: 7501.5532\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7363.4160 - mae: 7363.4160\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7295.4478 - mae: 7295.4478\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7569.8813 - mae: 7569.8813\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7548.1997 - mae: 7548.1997\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7424.3975 - mae: 7424.3975\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7529.7734 - mae: 7529.7734\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7467.3232 - mae: 7467.3232\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7635.9292 - mae: 7635.9292\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7536.8398 - mae: 7536.8398\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7616.5859 - mae: 7616.5859\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7439.4941 - mae: 7439.4941\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7538.0151 - mae: 7538.0151\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7415.1470 - mae: 7415.1470\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7420.6938 - mae: 7420.6938\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7509.9839 - mae: 7509.9839\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7541.1133 - mae: 7541.1133\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7467.8643 - mae: 7467.8643\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7389.3560 - mae: 7389.3560\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7499.7749 - mae: 7499.7749\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7523.9282 - mae: 7523.9282\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7243.3115 - mae: 7243.3115\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7429.5864 - mae: 7429.5864\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7313.3999 - mae: 7313.3999\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7526.3877 - mae: 7526.3877\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7542.2666 - mae: 7542.2666\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7576.9277 - mae: 7576.9277\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7546.4048 - mae: 7546.4048\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7351.2261 - mae: 7351.2261\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7302.1436 - mae: 7302.1436\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7393.0879 - mae: 7393.0879\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7442.2881 - mae: 7442.2881\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7492.6782 - mae: 7492.6782\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7561.9165 - mae: 7561.9165\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7340.5137 - mae: 7340.5137\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7496.0845 - mae: 7496.0845\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7617.0303 - mae: 7617.0303\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7641.1948 - mae: 7641.1948\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7084.2744 - mae: 7084.2744\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7240.4902 - mae: 7240.4902\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7283.4888 - mae: 7283.4888\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7335.5083 - mae: 7335.5083\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7275.6392 - mae: 7275.6392\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7313.1860 - mae: 7313.1860\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7485.7588 - mae: 7485.7588\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7352.2803 - mae: 7352.2803\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7520.5703 - mae: 7520.5703\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7279.3779 - mae: 7279.3779\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7273.8477 - mae: 7273.8477\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7176.5215 - mae: 7176.5215\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7425.6289 - mae: 7425.6289\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7403.1294 - mae: 7403.1294\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7356.0088 - mae: 7356.0088\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7484.7271 - mae: 7484.7271\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7217.6074 - mae: 7217.6074\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7261.0000 - mae: 7261.0000\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7134.1562 - mae: 7134.1562\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7083.4360 - mae: 7083.4360\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7254.1782 - mae: 7254.1782\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7268.7456 - mae: 7268.7456\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7470.5220 - mae: 7470.5220\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7210.9536 - mae: 7210.9536\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7395.6816 - mae: 7395.6816\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7328.0884 - mae: 7328.0884\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7230.4380 - mae: 7230.4380\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7261.3936 - mae: 7261.3936\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7342.5684 - mae: 7342.5684\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7106.1714 - mae: 7106.1714\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6b1aaf4610>"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKYda_kgz3Kg",
        "outputId": "b4ffc0d5-f2f5-4d98-c74e-140267db788e"
      },
      "source": [
        "# Check the results of insurance model on the test model\n",
        "insurance_model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 7023.3291 - mae: 7023.3291\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7023.3291015625, 7023.3291015625]"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hamDTK9N0LYp",
        "outputId": "9fce8133-7947-4e83-c400-b2cd24293ce4"
      },
      "source": [
        "y_train.median()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9575.4421"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzgcEkZV0T5A",
        "outputId": "e4b33b73-d6c3-4dbd-f4de-10ba7c39fe02"
      },
      "source": [
        "y_train.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13346.089736364489"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNwQmcjH0lFM"
      },
      "source": [
        "Right now it looks like our model is ot performing very well so we will try to improve it by:\n",
        "1. Adding a layer.\n",
        "2. Training it for longer (200 epochs).\n",
        "3. Changing the optimizer SGD to Adam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jCTFWld0ctd",
        "outputId": "0c028291-cd76-4cb4-cffb-2818afddf5aa"
      },
      "source": [
        "# Build a neuaral network\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1.Create a model\n",
        "insurance_model_2 = tf.keras.Sequential([\n",
        "                                       tf.keras.layers.Dense(100),\n",
        "                                       tf.keras.layers.Dense(10),\n",
        "                                       tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model_2.compile(loss=tf.keras.losses.mae,\n",
        "                        optimizer=tf.keras.optimizers.Adam(),\n",
        "                        metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "history = insurance_model_2.fit(X_train, y_train, epochs=200, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13273.1602 - mae: 13273.1602\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13104.4297 - mae: 13104.4297\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12749.5420 - mae: 12749.5420\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12055.7510 - mae: 12055.7510\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10905.8154 - mae: 10905.8154\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9457.7217 - mae: 9457.7217\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8147.6543 - mae: 8147.6543\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7528.8408 - mae: 7528.8408\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7429.1528 - mae: 7429.1528\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7409.0811 - mae: 7409.0811\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7390.8042 - mae: 7390.8042\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7368.9180 - mae: 7368.9180\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7348.5195 - mae: 7348.5195\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7326.4893 - mae: 7326.4893\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7307.5815 - mae: 7307.5815\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7285.7734 - mae: 7285.7734\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7265.7104 - mae: 7265.7104\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7242.5488 - mae: 7242.5488\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7220.5068 - mae: 7220.5068\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7197.1978 - mae: 7197.1978\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7179.0195 - mae: 7179.0195\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7151.2104 - mae: 7151.2104\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7126.4639 - mae: 7126.4639\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7101.9199 - mae: 7101.9199\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7084.3379 - mae: 7084.3379\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7052.3291 - mae: 7052.3291\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7024.3501 - mae: 7024.3501\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6996.6963 - mae: 6996.6963\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6969.0112 - mae: 6969.0112\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6942.1899 - mae: 6942.1899\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6911.7280 - mae: 6911.7280\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6884.0205 - mae: 6884.0205\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6853.4648 - mae: 6853.4648\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6823.0674 - mae: 6823.0674\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6789.6855 - mae: 6789.6855\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6755.7646 - mae: 6755.7646\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6720.2026 - mae: 6720.2026\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6689.7158 - mae: 6689.7158\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6652.4614 - mae: 6652.4614\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6618.1006 - mae: 6618.1006\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6585.8643 - mae: 6585.8643\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6559.4956 - mae: 6559.4956\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6530.0444 - mae: 6530.0444\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6506.8071 - mae: 6506.8071\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6493.5718 - mae: 6493.5718\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6475.9258 - mae: 6475.9258\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6458.8979 - mae: 6458.8979\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6445.1494 - mae: 6445.1494\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6430.9639 - mae: 6430.9639\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6417.7510 - mae: 6417.7510\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6403.2759 - mae: 6403.2759\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6392.4141 - mae: 6392.4141\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6378.7451 - mae: 6378.7451\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6364.9131 - mae: 6364.9131\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6351.5269 - mae: 6351.5269\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6337.6602 - mae: 6337.6602\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6324.8369 - mae: 6324.8369\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6310.1948 - mae: 6310.1948\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6295.6035 - mae: 6295.6035\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6284.8696 - mae: 6284.8696\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6265.6411 - mae: 6265.6411\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6253.0103 - mae: 6253.0103\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6234.9292 - mae: 6234.9292\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6218.0430 - mae: 6218.0430\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6201.1899 - mae: 6201.1899\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6183.9590 - mae: 6183.9590\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6171.2993 - mae: 6171.2993\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6148.8398 - mae: 6148.8398\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6132.5981 - mae: 6132.5981\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6112.3848 - mae: 6112.3848\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6092.7202 - mae: 6092.7202\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6073.7422 - mae: 6073.7422\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6059.4873 - mae: 6059.4873\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6031.3848 - mae: 6031.3848\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6010.3350 - mae: 6010.3350\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5995.2178 - mae: 5995.2178\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5963.0718 - mae: 5963.0718\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5940.0605 - mae: 5940.0605\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5915.1064 - mae: 5915.1064\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5887.9990 - mae: 5887.9990\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5861.6992 - mae: 5861.6992\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5834.3066 - mae: 5834.3066\n",
            "Epoch 83/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5805.8237 - mae: 5805.8237\n",
            "Epoch 84/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5772.3232 - mae: 5772.3232\n",
            "Epoch 85/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5745.1514 - mae: 5745.1514\n",
            "Epoch 86/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5711.3477 - mae: 5711.3477\n",
            "Epoch 87/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5674.5215 - mae: 5674.5215\n",
            "Epoch 88/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5639.4927 - mae: 5639.4927\n",
            "Epoch 89/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5600.6655 - mae: 5600.6655\n",
            "Epoch 90/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5559.4326 - mae: 5559.4326\n",
            "Epoch 91/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5523.6187 - mae: 5523.6187\n",
            "Epoch 92/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5474.1250 - mae: 5474.1250\n",
            "Epoch 93/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5432.2661 - mae: 5432.2661\n",
            "Epoch 94/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5386.0527 - mae: 5386.0527\n",
            "Epoch 95/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5333.1812 - mae: 5333.1812\n",
            "Epoch 96/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5288.8159 - mae: 5288.8159\n",
            "Epoch 97/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5234.6792 - mae: 5234.6792\n",
            "Epoch 98/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5170.9360 - mae: 5170.9360\n",
            "Epoch 99/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5112.9443 - mae: 5112.9443\n",
            "Epoch 100/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5059.8643 - mae: 5059.8643\n",
            "Epoch 101/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4987.6191 - mae: 4987.6191\n",
            "Epoch 102/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4915.2910 - mae: 4915.2910\n",
            "Epoch 103/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4847.3599 - mae: 4847.3599\n",
            "Epoch 104/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4768.0151 - mae: 4768.0151\n",
            "Epoch 105/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4683.4727 - mae: 4683.4727\n",
            "Epoch 106/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4600.5054 - mae: 4600.5054\n",
            "Epoch 107/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4513.1436 - mae: 4513.1436\n",
            "Epoch 108/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4422.2983 - mae: 4422.2983\n",
            "Epoch 109/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4339.9600 - mae: 4339.9600\n",
            "Epoch 110/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4254.3916 - mae: 4254.3916\n",
            "Epoch 111/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4173.1797 - mae: 4173.1797\n",
            "Epoch 112/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4102.2939 - mae: 4102.2939\n",
            "Epoch 113/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4031.9592 - mae: 4031.9592\n",
            "Epoch 114/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3986.0220 - mae: 3986.0220\n",
            "Epoch 115/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3943.2346 - mae: 3943.2346\n",
            "Epoch 116/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3918.8977 - mae: 3918.8977\n",
            "Epoch 117/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3895.5610 - mae: 3895.5610\n",
            "Epoch 118/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3869.5679 - mae: 3869.5679\n",
            "Epoch 119/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3850.2136 - mae: 3850.2136\n",
            "Epoch 120/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3834.7349 - mae: 3834.7349\n",
            "Epoch 121/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3827.0952 - mae: 3827.0952\n",
            "Epoch 122/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3821.6382 - mae: 3821.6382\n",
            "Epoch 123/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3813.8315 - mae: 3813.8315\n",
            "Epoch 124/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3805.7307 - mae: 3805.7307\n",
            "Epoch 125/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3794.7090 - mae: 3794.7090\n",
            "Epoch 126/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3804.4946 - mae: 3804.4946\n",
            "Epoch 127/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3796.0596 - mae: 3796.0596\n",
            "Epoch 128/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3791.0422 - mae: 3791.0422\n",
            "Epoch 129/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3800.0696 - mae: 3800.0696\n",
            "Epoch 130/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3788.5005 - mae: 3788.5005\n",
            "Epoch 131/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3780.8442 - mae: 3780.8442\n",
            "Epoch 132/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3774.5413 - mae: 3774.5413\n",
            "Epoch 133/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3771.0156 - mae: 3771.0156\n",
            "Epoch 134/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3769.3762 - mae: 3769.3762\n",
            "Epoch 135/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3766.7610 - mae: 3766.7610\n",
            "Epoch 136/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3765.5508 - mae: 3765.5508\n",
            "Epoch 137/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3774.5032 - mae: 3774.5032\n",
            "Epoch 138/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3785.3909 - mae: 3785.3909\n",
            "Epoch 139/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3761.1299 - mae: 3761.1299\n",
            "Epoch 140/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3764.1753 - mae: 3764.1753\n",
            "Epoch 141/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3763.9250 - mae: 3763.9250\n",
            "Epoch 142/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3762.7959 - mae: 3762.7959\n",
            "Epoch 143/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3754.4397 - mae: 3754.4397\n",
            "Epoch 144/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3750.3347 - mae: 3750.3347\n",
            "Epoch 145/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3750.4006 - mae: 3750.4006\n",
            "Epoch 146/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3755.4736 - mae: 3755.4736\n",
            "Epoch 147/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3750.3223 - mae: 3750.3223\n",
            "Epoch 148/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3758.1089 - mae: 3758.1089\n",
            "Epoch 149/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3743.4858 - mae: 3743.4858\n",
            "Epoch 150/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3738.5342 - mae: 3738.5342\n",
            "Epoch 151/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3740.1384 - mae: 3740.1384\n",
            "Epoch 152/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3742.4954 - mae: 3742.4954\n",
            "Epoch 153/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3744.4399 - mae: 3744.4399\n",
            "Epoch 154/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3737.1824 - mae: 3737.1824\n",
            "Epoch 155/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3737.6541 - mae: 3737.6541\n",
            "Epoch 156/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3737.1663 - mae: 3737.1663\n",
            "Epoch 157/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3733.1101 - mae: 3733.1101\n",
            "Epoch 158/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3729.5813 - mae: 3729.5813\n",
            "Epoch 159/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3725.9053 - mae: 3725.9053\n",
            "Epoch 160/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3733.2817 - mae: 3733.2817\n",
            "Epoch 161/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3728.2559 - mae: 3728.2559\n",
            "Epoch 162/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3724.5825 - mae: 3724.5825\n",
            "Epoch 163/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3723.0806 - mae: 3723.0806\n",
            "Epoch 164/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3726.9475 - mae: 3726.9475\n",
            "Epoch 165/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3716.5430 - mae: 3716.5430\n",
            "Epoch 166/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3721.9155 - mae: 3721.9155\n",
            "Epoch 167/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3721.1814 - mae: 3721.1814\n",
            "Epoch 168/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3715.2456 - mae: 3715.2456\n",
            "Epoch 169/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3713.9756 - mae: 3713.9756\n",
            "Epoch 170/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3707.9922 - mae: 3707.9922\n",
            "Epoch 171/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3707.4158 - mae: 3707.4158\n",
            "Epoch 172/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3710.6833 - mae: 3710.6833\n",
            "Epoch 173/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3703.3618 - mae: 3703.3618\n",
            "Epoch 174/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3710.9385 - mae: 3710.9385\n",
            "Epoch 175/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3713.0417 - mae: 3713.0417\n",
            "Epoch 176/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3705.0571 - mae: 3705.0571\n",
            "Epoch 177/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3698.9333 - mae: 3698.9333\n",
            "Epoch 178/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3697.9983 - mae: 3697.9983\n",
            "Epoch 179/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3704.9150 - mae: 3704.9150\n",
            "Epoch 180/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3710.3679 - mae: 3710.3679\n",
            "Epoch 181/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3696.6482 - mae: 3696.6482\n",
            "Epoch 182/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3692.7329 - mae: 3692.7329\n",
            "Epoch 183/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3691.1655 - mae: 3691.1655\n",
            "Epoch 184/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3699.2437 - mae: 3699.2437\n",
            "Epoch 185/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3693.2480 - mae: 3693.2480\n",
            "Epoch 186/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3696.1387 - mae: 3696.1387\n",
            "Epoch 187/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3687.8640 - mae: 3687.8640\n",
            "Epoch 188/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3693.3562 - mae: 3693.3562\n",
            "Epoch 189/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3682.7324 - mae: 3682.7324\n",
            "Epoch 190/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3683.2891 - mae: 3683.2891\n",
            "Epoch 191/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3697.6536 - mae: 3697.6536\n",
            "Epoch 192/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3684.6665 - mae: 3684.6665\n",
            "Epoch 193/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3675.5154 - mae: 3675.5154\n",
            "Epoch 194/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3676.3923 - mae: 3676.3923\n",
            "Epoch 195/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3672.8452 - mae: 3672.8452\n",
            "Epoch 196/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3682.0283 - mae: 3682.0283\n",
            "Epoch 197/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3665.7961 - mae: 3665.7961\n",
            "Epoch 198/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3671.7419 - mae: 3671.7419\n",
            "Epoch 199/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3680.5464 - mae: 3680.5464\n",
            "Epoch 200/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3665.6401 - mae: 3665.6401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9NnMOKq3xN9"
      },
      "source": [
        ">  **Note:** For many problems, the [Adam optimizer](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) is a great starting choice. See Andrei Karpathy's \"Adam is safe\" point from[ A Recipe for Training Neural Networks](http://karpathy.github.io/2019/04/25/recipe/) for more."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "po67TXcR0z4o",
        "outputId": "dbb22e67-8dc4-496d-e326-58bcadca0cb1"
      },
      "source": [
        "# Check the results of insurance model on the test model\n",
        "insurance_model_2.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 3491.2961 - mae: 3491.2961\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3491.296142578125, 3491.296142578125]"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iWdOOqr07D4",
        "outputId": "43eb5a5c-44da-4533-ef04-81310ba5a662"
      },
      "source": [
        "y_train.median(), y_train.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9575.4421, 13346.089736364489)"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK94O16n21fk"
      },
      "source": [
        "We have defined history befor for fit to plot the graph of our model to check the performance. So, let's check that out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "yeGpM8pv1Ag6",
        "outputId": "e94ac0fe-a657-4151-b8b4-b100fbeb5c50"
      },
      "source": [
        "# Plot history/ loss curve/training curve\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epochs\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'epochs')"
            ]
          },
          "metadata": {},
          "execution_count": 147
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGkdNZUX4PCN"
      },
      "source": [
        "> ** Question:** How long should you train for?\n",
        "\n",
        "> It depends on what problem you're working on. Sometimes training won't take very long, other times it'll take longer than you expect. A common method is to set your model training for a very long time (e.g. 1000's of epochs) but set it up with an [EarlyStopping callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) so it stops automatically when it stops improving. We'll see this in another module."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h3jB9Xi4j_u"
      },
      "source": [
        "## Preprocessing data (Normalization and Standardization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8Uw54Mj5Hdp"
      },
      "source": [
        "Let us check the things we have done.\n",
        "1. Not all our data will be in numbers, so before building a model we need to do numerical encoding. \n",
        "2. We have to make sure all tensors are in the right shape. \n",
        "3. Scale features ([normalize](https://en.wikipedia.org/wiki/Normalization_(statistics)) and [standardize](https://en.wikipedia.org/wiki/Standardization), mostly normalization) \n",
        "\n",
        "Let's look at the 3rd point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "sndXXJJf3Ktw",
        "outputId": "b3de0449-6ba2-4ba1-9bdf-c8a0adf574dd"
      },
      "source": [
        "# Look at the dataset\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows  11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     bmi  ...  region_southeast  region_southwest\n",
              "0      19  27.900  ...                 0                 1\n",
              "1      18  33.770  ...                 1                 0\n",
              "2      28  33.000  ...                 1                 0\n",
              "3      33  22.705  ...                 0                 0\n",
              "4      32  28.880  ...                 0                 0\n",
              "...   ...     ...  ...               ...               ...\n",
              "1333   50  30.970  ...                 0                 0\n",
              "1334   18  31.920  ...                 0                 0\n",
              "1335   18  36.850  ...                 1                 0\n",
              "1336   21  25.800  ...                 0                 1\n",
              "1337   61  29.070  ...                 0                 0\n",
              "\n",
              "[1338 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNK_wZwJAsYq"
      },
      "source": [
        "We can see that 'age' and 'bmi' are at different scale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "JYN2mXnvAqOp",
        "outputId": "9ba08cf0-b376-448a-c3fb-7b37f66479c8"
      },
      "source": [
        "X[\"age\"].plot(kind=\"hist\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6b2a42a1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 150
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "aNOpu31BA3zh",
        "outputId": "8c02e549-9b3a-42a6-8020-2546fd0afeb0"
      },
      "source": [
        "X[\"bmi\"].plot(kind=\"hist\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6b2a4036d0>"
            ]
          },
          "metadata": {},
          "execution_count": 151
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50JZvACUA_c8"
      },
      "source": [
        "We want to get both of them at the same scale. This is where normalization comes in. It scales the features between 0 and 1 and perserves all the distribution.\n",
        "\n",
        "Other is standardization which removes the mean and divides each value by [standard deviation](https://en.wikipedia.org/wiki/Standard_deviation). This reduces the effect of outliers.\n",
        "\n",
        "In terms of scaling values, neural networks tend to prefer normalization and often you'll see that neural networks perform well with minimum feature values.\n",
        "\n",
        "These scaling techniques are called `Feature Scaling`.\n",
        "\n",
        "If not sure which one to use, you can try both and see which perform well.\n",
        "\n",
        " **Resources:** Look at the following resources to understand better:\n",
        "* [Scikit-Learn's documentation on preprocessing data.](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-data)\n",
        "* [Scale, Standardize or Normalize with Scikit-Learn by Jeff Hale.](https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "IXaRnK8GA-fJ",
        "outputId": "907ed65b-ddd3-418b-b00f-8997659d7de0"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# Read in the insurance dataset and check the dataset\n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
        "insurance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows  7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     sex     bmi  children smoker     region      charges\n",
              "0      19  female  27.900         0    yes  southwest  16884.92400\n",
              "1      18    male  33.770         1     no  southeast   1725.55230\n",
              "2      28    male  33.000         3     no  southeast   4449.46200\n",
              "3      33    male  22.705         0     no  northwest  21984.47061\n",
              "4      32    male  28.880         0     no  northwest   3866.85520\n",
              "...   ...     ...     ...       ...    ...        ...          ...\n",
              "1333   50    male  30.970         3     no  northwest  10600.54830\n",
              "1334   18  female  31.920         0     no  northeast   2205.98080\n",
              "1335   18  female  36.850         0     no  southeast   1629.83350\n",
              "1336   21  female  25.800         0     no  southwest   2007.94500\n",
              "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
              "\n",
              "[1338 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqOiyCwMEHCe"
      },
      "source": [
        "To prepare our data, we can borrow a few classes from scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-Ofm6znEBDt"
      },
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder # MixMaxScalar for normalization, OneHotEncoder for numerical encoding\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create a column transformer\n",
        "ct = make_column_transformer(\n",
        "    (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]), # turn all values in these columns between 0 and 1\n",
        "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\", \"smoker\", \"region\"])  # Numerical encode the strings\n",
        ")\n",
        "\n",
        "# Create X & y\n",
        "X = insurance.drop(\"charges\", axis=1)\n",
        "y = insurance[\"charges\"]\n",
        "\n",
        "# Build our train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the column transformer to our training data\n",
        "ct.fit(X_train)\n",
        "\n",
        "# Transform training data and test data with normalization and OneHotEncoder\n",
        "X_train_normal = ct.transform(X_train)\n",
        "X_test_normal = ct.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_m5w_JeGmFb",
        "outputId": "f2f8bc31-60e0-4c22-f055-57b866bbcee6"
      },
      "source": [
        "# What does our data look like before?\n",
        "X_train.loc[0] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                19\n",
              "sex            female\n",
              "bmi              27.9\n",
              "children            0\n",
              "smoker            yes\n",
              "region      southwest\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-LnLP_KG9Fp",
        "outputId": "c7776c20-cfa7-4022-85df-07533f4a714a"
      },
      "source": [
        "# What does our data look like now?\n",
        "X_train_normal"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.60869565, 0.10734463, 0.4       , ..., 1.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.63043478, 0.22491256, 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.73913043, 0.23944041, 0.        , ..., 0.        , 1.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.86956522, 0.24791499, 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.41304348, 0.85122411, 0.4       , ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       [0.80434783, 0.37503363, 0.        , ..., 0.        , 0.        ,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhoGng9YHWNM"
      },
      "source": [
        "Now, our data is in numerical format and this means we can pass it to our neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzpH2rMNHA1S",
        "outputId": "d640288f-4762-4208-9b03-2722945cc24d"
      },
      "source": [
        "# Let's check the shapes before and now\n",
        "X_train.shape, X_train_normal.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1070, 6), (1070, 11))"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtCNoRIXHuaQ"
      },
      "source": [
        "Our data has been normalized and one hot encoded. Now let's build a neural network model and see how it goes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BQ3B4BPHsGZ",
        "outputId": "f7309011-9ba1-42e2-d526-f23921a6a12c"
      },
      "source": [
        "# Build a neural network model to fit our normalized data\n",
        "\n",
        "# Create the model\n",
        "insurance_model_3 =  tf.keras.Sequential([\n",
        "                                          tf.keras.layers.Dense(100),\n",
        "                                          tf.keras.layers.Dense(10),\n",
        "                                          tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "insurance_model_3.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer=tf.keras.optimizers.Adam(),\n",
        "                          metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model\n",
        "insurance_model_3.fit(X_train_normal, y_train, epochs=200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13344.1953 - mae: 13344.1953\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13336.0244 - mae: 13336.0244\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13315.7998 - mae: 13315.7998\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 13272.6104 - mae: 13272.6104\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13195.0557 - mae: 13195.0557\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13071.6191 - mae: 13071.6191\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12891.7305 - mae: 12891.7305\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12645.2568 - mae: 12645.2568\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12322.0635 - mae: 12322.0635\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 11917.5869 - mae: 11917.5869\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 11441.0205 - mae: 11441.0205\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10932.2822 - mae: 10932.2822\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10428.0137 - mae: 10428.0137\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9930.2148 - mae: 9930.2148\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9462.1064 - mae: 9462.1064\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9047.3145 - mae: 9047.3145\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8704.6455 - mae: 8704.6455\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8425.4453 - mae: 8425.4453\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8215.7998 - mae: 8215.7998\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8072.0645 - mae: 8072.0645\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7965.2261 - mae: 7965.2261\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7891.2065 - mae: 7891.2065\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7833.2490 - mae: 7833.2490\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7781.1089 - mae: 7781.1089\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7742.4561 - mae: 7742.4561\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7690.9902 - mae: 7690.9902\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7648.5977 - mae: 7648.5977\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7605.9473 - mae: 7605.9473\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7563.2129 - mae: 7563.2129\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7519.2827 - mae: 7519.2827\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7474.9087 - mae: 7474.9087\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7430.3247 - mae: 7430.3247\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7385.5000 - mae: 7385.5000\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7336.7554 - mae: 7336.7554\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7289.3345 - mae: 7289.3345\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7238.4790 - mae: 7238.4790\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7187.3750 - mae: 7187.3750\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7135.7700 - mae: 7135.7700\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7080.1147 - mae: 7080.1147\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7023.9062 - mae: 7023.9062\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6966.5869 - mae: 6966.5869\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6906.6494 - mae: 6906.6494\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6842.9678 - mae: 6842.9678\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6775.4565 - mae: 6775.4565\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6707.1353 - mae: 6707.1353\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6636.8691 - mae: 6636.8691\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6564.0698 - mae: 6564.0698\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6483.8320 - mae: 6483.8320\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6403.2886 - mae: 6403.2886\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6315.8594 - mae: 6315.8594\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6229.4751 - mae: 6229.4751\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6134.7720 - mae: 6134.7720\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6036.8682 - mae: 6036.8682\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5936.0244 - mae: 5936.0244\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5826.1030 - mae: 5826.1030\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5715.2559 - mae: 5715.2559\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5597.2158 - mae: 5597.2158\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5477.7920 - mae: 5477.7920\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5356.4468 - mae: 5356.4468\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5231.1157 - mae: 5231.1157\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5103.5747 - mae: 5103.5747\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4970.8081 - mae: 4970.8081\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4840.7021 - mae: 4840.7021\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4706.8218 - mae: 4706.8218\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4579.1650 - mae: 4579.1650\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4456.2500 - mae: 4456.2500\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4347.0459 - mae: 4347.0459\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4241.2432 - mae: 4241.2432\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4140.8784 - mae: 4140.8784\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4049.9897 - mae: 4049.9897\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3968.9314 - mae: 3968.9314\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3899.2390 - mae: 3899.2390\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3842.3716 - mae: 3842.3716\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3793.7485 - mae: 3793.7485\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3758.6997 - mae: 3758.6997\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3732.6936 - mae: 3732.6936\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3711.1316 - mae: 3711.1316\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3697.6313 - mae: 3697.6313\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3688.6216 - mae: 3688.6216\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3680.1223 - mae: 3680.1223\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3675.1311 - mae: 3675.1311\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3672.4456 - mae: 3672.4456\n",
            "Epoch 83/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3666.9646 - mae: 3666.9646\n",
            "Epoch 84/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3664.2593 - mae: 3664.2593\n",
            "Epoch 85/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3661.6926 - mae: 3661.6926\n",
            "Epoch 86/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3660.0469 - mae: 3660.0469\n",
            "Epoch 87/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3657.3691 - mae: 3657.3691\n",
            "Epoch 88/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3655.0474 - mae: 3655.0474\n",
            "Epoch 89/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3654.0378 - mae: 3654.0378\n",
            "Epoch 90/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3652.1672 - mae: 3652.1672\n",
            "Epoch 91/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3649.0151 - mae: 3649.0151\n",
            "Epoch 92/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3648.4160 - mae: 3648.4160\n",
            "Epoch 93/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3646.1506 - mae: 3646.1506\n",
            "Epoch 94/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3644.4368 - mae: 3644.4368\n",
            "Epoch 95/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3645.5413 - mae: 3645.5413\n",
            "Epoch 96/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3642.5439 - mae: 3642.5439\n",
            "Epoch 97/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3639.8391 - mae: 3639.8391\n",
            "Epoch 98/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3638.0190 - mae: 3638.0190\n",
            "Epoch 99/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3637.2600 - mae: 3637.2600\n",
            "Epoch 100/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3635.8406 - mae: 3635.8406\n",
            "Epoch 101/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3632.9636 - mae: 3632.9636\n",
            "Epoch 102/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3630.4470 - mae: 3630.4470\n",
            "Epoch 103/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3629.3398 - mae: 3629.3398\n",
            "Epoch 104/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3626.8687 - mae: 3626.8687\n",
            "Epoch 105/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3625.3186 - mae: 3625.3186\n",
            "Epoch 106/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3623.9751 - mae: 3623.9751\n",
            "Epoch 107/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3623.5037 - mae: 3623.5037\n",
            "Epoch 108/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3620.8750 - mae: 3620.8750\n",
            "Epoch 109/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3621.1204 - mae: 3621.1204\n",
            "Epoch 110/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3617.9202 - mae: 3617.9202\n",
            "Epoch 111/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3615.0491 - mae: 3615.0491\n",
            "Epoch 112/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3613.0264 - mae: 3613.0264\n",
            "Epoch 113/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3611.5256 - mae: 3611.5256\n",
            "Epoch 114/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3610.6526 - mae: 3610.6526\n",
            "Epoch 115/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3608.9319 - mae: 3608.9319\n",
            "Epoch 116/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3607.5872 - mae: 3607.5872\n",
            "Epoch 117/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3604.4832 - mae: 3604.4832\n",
            "Epoch 118/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3600.8352 - mae: 3600.8352\n",
            "Epoch 119/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3603.1016 - mae: 3603.1016\n",
            "Epoch 120/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3599.7363 - mae: 3599.7363\n",
            "Epoch 121/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3594.9146 - mae: 3594.9146\n",
            "Epoch 122/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3594.2988 - mae: 3594.2988\n",
            "Epoch 123/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3592.2515 - mae: 3592.2515\n",
            "Epoch 124/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3590.0203 - mae: 3590.0203\n",
            "Epoch 125/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3588.0627 - mae: 3588.0627\n",
            "Epoch 126/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3587.1316 - mae: 3587.1316\n",
            "Epoch 127/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3587.7820 - mae: 3587.7820\n",
            "Epoch 128/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3583.7329 - mae: 3583.7329\n",
            "Epoch 129/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3582.3674 - mae: 3582.3674\n",
            "Epoch 130/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3578.7654 - mae: 3578.7654\n",
            "Epoch 131/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3577.3298 - mae: 3577.3298\n",
            "Epoch 132/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3574.4866 - mae: 3574.4866\n",
            "Epoch 133/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3572.8672 - mae: 3572.8672\n",
            "Epoch 134/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3570.7810 - mae: 3570.7810\n",
            "Epoch 135/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3568.8713 - mae: 3568.8713\n",
            "Epoch 136/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3567.4231 - mae: 3567.4231\n",
            "Epoch 137/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3565.8130 - mae: 3565.8130\n",
            "Epoch 138/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3563.4604 - mae: 3563.4604\n",
            "Epoch 139/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3562.7104 - mae: 3562.7104\n",
            "Epoch 140/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3560.4478 - mae: 3560.4478\n",
            "Epoch 141/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3560.5574 - mae: 3560.5574\n",
            "Epoch 142/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3557.6008 - mae: 3557.6008\n",
            "Epoch 143/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3557.6165 - mae: 3557.6165\n",
            "Epoch 144/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3554.5227 - mae: 3554.5227\n",
            "Epoch 145/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3552.8125 - mae: 3552.8125\n",
            "Epoch 146/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3552.9773 - mae: 3552.9773\n",
            "Epoch 147/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3550.4343 - mae: 3550.4343\n",
            "Epoch 148/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3549.1819 - mae: 3549.1819\n",
            "Epoch 149/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3546.3833 - mae: 3546.3833\n",
            "Epoch 150/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3546.2117 - mae: 3546.2117\n",
            "Epoch 151/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3544.3323 - mae: 3544.3323\n",
            "Epoch 152/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3542.8613 - mae: 3542.8613\n",
            "Epoch 153/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3541.2527 - mae: 3541.2527\n",
            "Epoch 154/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3542.5078 - mae: 3542.5078\n",
            "Epoch 155/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3540.4749 - mae: 3540.4749\n",
            "Epoch 156/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3538.3296 - mae: 3538.3296\n",
            "Epoch 157/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3537.0439 - mae: 3537.0439\n",
            "Epoch 158/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3533.7908 - mae: 3533.7908\n",
            "Epoch 159/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3532.3899 - mae: 3532.3899\n",
            "Epoch 160/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3532.2634 - mae: 3532.2634\n",
            "Epoch 161/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3529.0342 - mae: 3529.0342\n",
            "Epoch 162/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3528.4370 - mae: 3528.4370\n",
            "Epoch 163/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3526.9495 - mae: 3526.9495\n",
            "Epoch 164/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3525.7698 - mae: 3525.7698\n",
            "Epoch 165/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3523.7791 - mae: 3523.7791\n",
            "Epoch 166/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3522.0945 - mae: 3522.0945\n",
            "Epoch 167/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3521.3950 - mae: 3521.3950\n",
            "Epoch 168/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3520.4844 - mae: 3520.4844\n",
            "Epoch 169/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3518.9072 - mae: 3518.9072\n",
            "Epoch 170/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3517.5786 - mae: 3517.5786\n",
            "Epoch 171/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3516.8831 - mae: 3516.8831\n",
            "Epoch 172/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3515.3459 - mae: 3515.3459\n",
            "Epoch 173/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3514.2173 - mae: 3514.2173\n",
            "Epoch 174/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3512.9995 - mae: 3512.9995\n",
            "Epoch 175/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3511.7002 - mae: 3511.7002\n",
            "Epoch 176/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3511.6428 - mae: 3511.6428\n",
            "Epoch 177/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3511.9995 - mae: 3511.9995\n",
            "Epoch 178/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3509.4922 - mae: 3509.4922\n",
            "Epoch 179/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3511.4856 - mae: 3511.4856\n",
            "Epoch 180/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3506.5195 - mae: 3506.5195\n",
            "Epoch 181/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3504.4392 - mae: 3504.4392\n",
            "Epoch 182/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3503.8303 - mae: 3503.8303\n",
            "Epoch 183/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3501.8640 - mae: 3501.8640\n",
            "Epoch 184/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3501.2224 - mae: 3501.2224\n",
            "Epoch 185/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3500.7986 - mae: 3500.7986\n",
            "Epoch 186/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3498.4751 - mae: 3498.4751\n",
            "Epoch 187/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3498.5942 - mae: 3498.5942\n",
            "Epoch 188/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3496.0005 - mae: 3496.0005\n",
            "Epoch 189/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3494.6711 - mae: 3494.6711\n",
            "Epoch 190/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3495.7971 - mae: 3495.7971\n",
            "Epoch 191/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3501.7834 - mae: 3501.7834\n",
            "Epoch 192/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3491.3105 - mae: 3491.3105\n",
            "Epoch 193/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3491.5625 - mae: 3491.5625\n",
            "Epoch 194/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3488.1243 - mae: 3488.1243\n",
            "Epoch 195/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3487.2180 - mae: 3487.2180\n",
            "Epoch 196/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3488.7407 - mae: 3488.7407\n",
            "Epoch 197/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3485.3831 - mae: 3485.3831\n",
            "Epoch 198/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3483.9092 - mae: 3483.9092\n",
            "Epoch 199/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3482.9478 - mae: 3482.9478\n",
            "Epoch 200/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3483.4512 - mae: 3483.4512\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6b29a1e750>"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M42RvlpdItki",
        "outputId": "1bebb0e8-bd3d-4b04-87f0-84457481de12"
      },
      "source": [
        "# Evaluate our insurance model trained on normalized data\n",
        "insurance_model_3.evaluate(X_test_normal, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 3170.4167 - mae: 3170.4167\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3170.416748046875, 3170.416748046875]"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjnGq8NeJZzp"
      },
      "source": [
        "# Insurance model 2 results\n",
        "# 9/9 [==============================] - 0s 2ms/step - loss: 3491.2961 - mae: 3491.2961"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaqEKRZlJjPa"
      },
      "source": [
        "We can see that there are some improvements(not that much) but we can improve the results by more improvements in our model.\n",
        "\n",
        "We can conclude that normalization does not garuntee much improvements in our results much we can definitely try to improve our results.\n",
        "\n",
        "But there is one huge benifit of normalization which is that our model **converges faster**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_Ei-AFjJErJ",
        "outputId": "9cf6aad9-dc64-4d05-81ac-6991c23c98aa"
      },
      "source": [
        "insurance_model_3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_51 (Dense)             (None, 100)               1200      \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 10)                1010      \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 2,221\n",
            "Trainable params: 2,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6IsIElFJICq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}